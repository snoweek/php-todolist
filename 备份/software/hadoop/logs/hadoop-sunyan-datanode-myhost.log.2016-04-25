2016-04-25 08:17:16,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 08:17:16,627 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 08:17:16,641 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 08:17:16,642 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 08:17:16,642 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 08:17:16,763 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 08:17:16,781 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 08:17:18,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:19,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:20,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:21,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:22,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:23,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:24,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:25,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:26,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:27,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:27,373 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:17:29,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:30,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:31,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:32,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:33,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:34,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:35,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:36,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:37,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:38,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:38,391 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:17:40,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:41,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:42,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:43,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:44,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:45,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:46,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:47,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:48,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:49,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:49,410 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:17:51,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:52,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:53,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:54,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:55,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:56,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:57,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:58,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:17:59,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:00,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:00,429 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:02,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:03,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:04,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:05,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:06,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:07,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:08,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:09,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:10,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:11,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:11,447 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:13,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:14,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:15,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:16,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:17,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:18,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:19,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:20,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:21,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:22,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:22,467 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:24,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:25,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:26,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:27,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:28,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:29,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:30,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:31,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:32,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:33,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:33,486 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:35,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:36,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:37,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:38,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:39,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:40,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:41,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:42,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:43,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:44,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:44,505 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:46,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:47,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:48,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:49,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:50,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:51,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:52,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:53,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:54,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:55,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:55,522 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:18:57,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:58,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:18:59,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:00,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:01,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:02,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:03,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:04,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:05,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:06,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:06,540 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:19:08,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:09,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:10,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:11,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:12,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:13,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:14,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:15,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:16,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:17,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:17,558 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:19:19,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:20,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:21,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:22,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:23,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:24,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:25,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:26,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:27,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:28,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:28,576 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:19:30,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:31,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:32,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:33,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:34,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:35,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:36,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:37,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:38,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:39,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:39,593 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:19:41,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:42,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:43,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:44,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:45,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:46,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:47,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:48,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:49,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:50,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:50,610 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:19:52,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:53,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:54,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:55,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:56,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:57,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:58,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:19:59,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:00,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:01,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:01,627 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:03,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:04,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:05,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:06,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:07,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:08,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:09,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:10,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:11,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:12,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:12,647 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:14,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:15,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:16,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:17,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:18,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:19,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:20,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:21,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:22,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:23,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:23,665 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:25,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:26,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:27,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:28,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:29,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:30,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:31,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:32,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:33,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:34,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:34,683 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:36,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:37,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:38,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:39,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:40,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:41,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:42,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:43,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:44,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:45,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:45,701 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:47,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:48,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:49,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:50,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:51,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:52,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:53,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:54,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:55,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:56,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:56,720 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:20:58,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:20:59,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:00,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:01,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:02,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:03,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:04,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:05,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:06,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:07,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:07,737 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:21:09,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:10,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:11,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:12,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:13,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:14,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:15,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:16,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:17,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:18,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:18,756 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:21:20,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:21,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:22,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:23,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:24,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:25,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:26,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:27,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:28,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:29,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:29,775 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:21:31,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:32,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:33,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:34,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:35,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:36,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:37,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:38,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:39,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:40,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:40,794 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:21:42,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:43,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:44,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:45,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:46,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:47,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:48,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:49,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:50,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:51,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:51,810 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:21:53,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:54,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:55,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:56,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:57,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:58,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:21:59,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:00,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:01,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:02,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:02,827 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:04,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:05,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:06,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:07,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:08,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:09,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:10,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:11,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:12,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:13,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:13,841 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:15,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:16,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:17,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:18,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:19,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:20,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:21,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:22,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:23,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:24,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:24,857 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:26,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:27,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:28,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:29,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:30,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:31,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:32,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:33,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:34,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:35,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:35,873 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:37,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:38,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:39,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:40,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:41,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:42,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:43,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:44,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:45,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:46,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:46,889 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:48,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:49,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:50,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:51,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:52,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:53,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:54,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:55,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:56,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:57,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:22:57,904 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:22:59,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:00,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:01,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:02,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:03,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:04,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:05,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:06,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:07,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:08,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:08,920 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:23:10,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:11,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:12,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:13,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:14,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:15,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:16,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:17,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:18,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:19,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:19,936 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:23:21,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:22,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:23,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:24,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:25,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:26,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:27,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:28,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:29,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:30,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:30,952 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:23:32,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:33,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:34,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:35,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:36,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:37,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:38,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:39,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:40,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:41,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:41,969 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:23:43,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:44,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:45,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:46,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:47,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:48,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:49,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:50,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:51,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:52,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:52,985 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:23:54,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:55,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:56,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:57,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:58,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:23:59,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:00,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:01,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:02,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:03,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:03,999 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:24:06,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:07,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:08,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:09,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:10,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:11,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:12,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:13,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:14,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:15,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:15,014 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:24:17,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:18,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:19,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:20,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:21,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:22,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:23,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:24,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:25,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:26,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:26,030 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:24:28,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:29,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:30,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:31,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:32,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:33,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:34,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:35,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:36,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:37,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:37,046 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:24:39,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:40,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:41,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:42,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:43,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:44,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:45,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:46,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:47,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:48,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:48,061 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:24:50,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:51,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:52,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:53,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:54,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:55,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:56,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:57,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:58,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:59,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:24:59,077 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:01,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:02,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:03,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:04,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:05,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:06,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:07,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:08,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:09,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:10,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:10,092 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:12,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:13,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:14,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:15,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:16,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:17,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:18,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:19,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:20,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:21,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:21,108 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:23,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:24,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:25,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:26,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:27,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:28,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:29,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:30,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:31,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:32,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:32,123 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:34,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:35,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:36,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:37,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:38,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:39,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:40,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:41,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:42,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:43,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:43,139 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:45,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:46,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:47,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:48,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:49,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:50,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:51,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:52,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:53,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:54,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:54,158 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:25:56,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:57,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:58,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:25:59,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:00,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:01,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:02,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:03,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:04,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:05,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:05,173 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:26:07,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:08,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:09,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:10,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:11,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:12,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:13,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:14,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:15,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:16,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:16,187 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:26:18,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:19,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:20,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:21,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:22,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:23,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:24,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:25,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:26,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:27,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:27,202 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:26:29,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:30,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:31,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:32,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:33,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:34,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:35,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:36,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:37,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:38,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:38,217 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:26:40,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:41,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:42,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:43,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:44,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:45,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:46,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:47,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:48,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:49,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:49,232 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:26:51,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:52,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:53,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:54,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:55,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:56,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:57,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:58,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:26:59,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:00,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:00,246 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:02,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:03,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:04,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:05,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:06,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:07,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:08,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:09,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:10,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:11,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:11,261 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:13,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:14,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:15,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:16,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:17,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:18,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:19,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:20,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:21,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:22,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:22,277 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:24,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:25,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:26,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:27,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:28,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:29,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:30,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:31,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:32,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:33,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:33,291 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:35,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:36,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:37,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:38,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:39,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:40,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:41,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:42,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:43,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:44,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:44,307 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:46,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:47,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:48,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:49,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:50,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:51,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:52,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:53,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:54,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:55,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:55,323 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:27:57,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:58,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:27:59,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:00,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:01,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:02,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:03,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:04,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:05,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:06,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:06,340 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:28:08,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:09,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:10,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:11,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:12,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:13,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:14,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:15,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:16,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:17,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:17,355 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:28:19,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:20,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:21,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:22,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:23,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:24,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:25,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:26,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:27,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:28,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:28,369 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:28:30,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:31,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:32,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:33,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:34,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:35,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:36,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:37,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:38,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:39,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:39,384 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:28:41,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:42,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:43,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:44,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:45,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:46,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:47,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:48,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:49,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:50,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:50,398 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:28:52,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:53,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:54,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:55,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:56,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:57,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:58,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:28:59,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:00,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:01,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:01,414 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:03,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:04,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:05,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:06,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:07,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:08,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:09,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:10,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:11,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:12,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:12,430 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:14,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:15,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:16,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:17,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:18,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:19,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:20,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:21,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:22,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:23,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:23,445 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:25,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:26,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:27,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:28,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:29,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:30,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:31,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:32,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:33,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:34,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:34,459 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:36,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:37,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:38,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:39,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:40,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:41,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:42,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:43,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:44,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:45,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:45,473 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:47,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:48,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:49,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:50,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:51,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:52,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:53,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:54,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:55,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:56,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:56,488 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:29:58,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:29:59,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:00,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:01,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:02,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:03,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:04,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:05,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:06,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:07,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:07,504 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:30:09,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:10,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:11,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:12,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:13,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:14,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:15,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:16,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:17,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:18,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:18,519 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:30:20,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:21,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:22,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:23,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:24,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:25,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:26,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:27,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:28,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:29,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:29,533 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:30:31,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:32,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:33,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:34,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:35,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:36,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:37,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:38,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:39,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:40,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:40,547 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:30:42,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:43,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:44,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:45,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:46,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:47,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:48,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:49,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:50,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:51,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:51,561 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:30:53,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:54,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:55,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:56,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:57,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:58,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:30:59,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:00,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:01,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:02,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:02,575 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:04,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:05,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:06,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:07,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:08,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:09,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:10,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:11,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:12,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:13,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:13,590 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:15,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:16,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:17,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:18,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:19,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:20,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:21,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:22,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:23,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:24,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:24,605 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:26,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:27,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:28,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:29,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:30,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:31,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:32,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:33,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:34,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:35,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:35,618 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:37,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:38,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:39,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:40,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:41,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:42,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:43,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:44,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:45,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:46,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:46,632 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:48,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:49,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:50,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:51,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:52,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:53,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:54,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:55,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:56,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:57,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:31:57,647 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:31:59,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:00,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:01,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:02,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:03,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:04,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:05,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:06,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:07,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:08,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:08,661 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:32:10,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:11,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:12,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:13,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:14,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:15,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:16,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:17,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:18,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:19,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:19,676 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:32:21,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:22,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:23,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:24,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:25,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:26,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:27,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:28,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:29,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:30,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:30,689 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:32:32,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:33,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:34,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:35,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:36,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:37,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:38,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:39,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:40,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:41,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:41,704 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:32:43,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:44,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:45,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:46,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:47,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:48,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:49,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:50,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:51,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:52,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:52,717 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:32:54,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:55,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:56,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:57,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:58,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:32:59,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:00,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:01,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:02,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:03,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:03,729 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:33:05,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:06,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:07,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:08,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:09,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:10,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:11,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:12,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:13,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:14,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:14,743 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:33:16,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:17,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:18,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:19,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:20,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:21,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:22,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:23,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:24,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:25,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:25,756 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:33:27,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:28,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:29,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:30,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:31,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:32,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:33,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:34,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:35,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:36,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:36,770 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:33:38,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:39,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:40,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:41,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:42,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:43,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:44,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:45,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:46,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:47,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:47,783 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:33:49,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:50,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:51,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:52,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:53,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:54,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:55,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:56,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:57,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:58,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:33:58,796 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:00,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:01,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:02,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:03,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:04,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:05,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:06,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:07,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:08,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:09,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:09,810 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:11,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:12,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:13,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:14,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:15,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:16,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:17,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:18,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:19,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:20,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:20,823 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:22,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:23,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:24,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:25,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:26,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:27,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:28,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:29,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:30,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:31,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:31,849 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:33,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:34,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:35,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:36,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:37,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:38,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:39,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:40,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:41,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:42,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:42,862 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:44,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:45,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:46,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:47,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:48,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:49,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:50,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:51,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:52,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:53,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:53,874 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:34:55,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:56,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:57,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:58,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:34:59,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:00,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:01,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:02,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:03,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:04,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:04,887 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:35:06,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:07,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:08,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:09,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:10,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:11,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:12,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:13,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:14,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:15,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:15,900 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:35:17,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:18,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:19,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:20,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:21,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:22,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:23,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:24,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:25,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:26,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:26,913 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:35:28,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:29,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:30,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:31,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:32,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:33,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:34,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:35,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:36,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:37,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:37,925 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:35:39,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:40,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:41,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:42,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:43,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:44,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:45,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:46,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:47,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:48,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:48,938 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:35:50,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:51,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:52,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:53,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:54,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:55,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:56,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:57,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:58,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:59,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:35:59,950 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:01,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:02,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:03,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:04,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:05,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:06,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:07,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:08,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:09,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:10,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:10,961 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:12,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:13,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:14,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:15,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:16,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:17,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:18,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:19,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:20,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:21,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:21,969 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:23,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:24,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:25,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:26,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:27,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:28,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:29,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:30,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:31,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:32,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:32,977 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:34,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:35,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:36,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:37,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:38,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:39,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:40,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:41,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:42,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:43,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:43,985 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:45,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:46,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:47,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:48,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:49,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:50,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:51,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:52,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:53,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:54,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:54,992 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:36:56,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:57,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:58,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:36:59,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:00,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:01,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:02,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:04,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:05,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:06,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:06,001 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:37:08,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:09,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:10,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:11,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:12,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:13,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:14,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:15,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:16,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:17,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:17,013 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:37:19,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:20,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:21,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:22,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:23,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:24,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:25,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:26,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:27,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:28,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:28,023 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:37:30,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:31,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:32,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:33,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:34,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:35,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:36,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:37,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:38,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:39,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:39,031 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:37:41,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:42,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:43,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:44,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:45,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:46,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:47,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:48,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:49,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:50,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:50,040 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:37:52,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:53,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:54,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:55,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:56,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:57,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:58,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:37:59,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:00,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:01,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:01,053 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:38:03,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:04,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:05,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:06,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:07,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:08,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:09,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:10,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:11,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:12,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:12,064 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:38:14,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:15,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:16,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:17,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:18,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:19,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:20,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:21,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:22,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:23,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:23,077 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:38:25,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:26,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:27,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:28,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:29,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:30,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:31,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:32,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:33,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:34,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:34,089 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:38:36,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:37,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:38,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:39,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:40,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:41,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:42,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:43,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:44,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:38:44,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
2016-04-25 08:39:22,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 08:39:22,963 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 08:39:22,972 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 08:39:22,973 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 08:39:22,973 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 08:39:23,083 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 08:39:23,087 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 08:39:24,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:25,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:26,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:27,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:28,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:29,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:30,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:31,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:32,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:33,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:33,312 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:39:35,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:36,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:37,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:38,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:39,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:40,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:41,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:42,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:43,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:44,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:44,327 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:39:46,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:47,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:48,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:49,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:50,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:51,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:52,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:53,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:54,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:55,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:55,345 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:39:57,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:58,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:39:59,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:00,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:01,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:02,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:03,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:04,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:05,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:06,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:06,363 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:40:08,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:09,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:10,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:11,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:12,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:13,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:14,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:15,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:16,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:17,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:17,381 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:40:19,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:20,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:21,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:22,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:23,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:24,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:25,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:26,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:27,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:28,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:28,399 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:40:30,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:31,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:32,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:33,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:34,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:35,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:36,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:37,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:38,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:39,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:39,413 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:40:41,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:42,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:43,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:44,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:45,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:46,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:47,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:48,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:49,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:50,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:50,429 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:40:52,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:53,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:54,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:55,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:56,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:57,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:58,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:40:59,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:00,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:01,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:01,444 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:03,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:04,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:05,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:06,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:07,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:08,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:09,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:10,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:11,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:12,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:12,458 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:14,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:15,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:16,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:17,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:18,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:19,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:20,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:21,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:22,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:23,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:23,474 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:25,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:26,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:27,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:28,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:29,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:30,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:31,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:32,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:33,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:34,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:34,493 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:36,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:37,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:38,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:39,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:40,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:41,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:42,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:43,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:44,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:45,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:45,511 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:47,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:48,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:49,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:50,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:51,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:52,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:53,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:54,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:55,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:56,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:56,528 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:41:58,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:41:59,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:00,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:01,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:02,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:03,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:04,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:05,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:06,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:07,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:07,546 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:42:09,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:10,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:11,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:12,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:13,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:14,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:15,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:16,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:17,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:18,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:18,562 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:42:20,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:21,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:22,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:23,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:24,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:25,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:26,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:27,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:28,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:29,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:29,576 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:42:31,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:32,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:33,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:34,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:35,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:36,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:37,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:38,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:39,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:40,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:40,591 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:42:42,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:43,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:44,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:42:45,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
2016-04-25 08:43:02,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 08:43:02,632 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 08:43:02,641 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 08:43:02,641 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 08:43:02,641 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 08:43:02,752 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 08:43:02,756 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 08:43:03,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:04,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:05,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:06,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:07,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:09,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:10,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:11,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:12,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:13,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:13,015 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:43:15,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:16,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:17,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:18,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:19,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:20,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:21,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:22,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:23,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:24,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:24,031 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:43:26,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:27,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:28,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:29,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:30,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:31,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:32,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:33,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:34,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:35,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:35,046 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:43:37,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:38,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:39,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:40,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:41,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:43:41,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
2016-04-25 08:44:12,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 08:44:12,170 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 08:44:12,178 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 08:44:12,179 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 08:44:12,179 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 08:44:12,290 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 08:44:12,294 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 08:44:13,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:14,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:15,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:16,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:17,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:18,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:19,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:20,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:21,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:22,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:22,535 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:44:24,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:25,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:26,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:27,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:28,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:29,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:30,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:31,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:32,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:33,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:33,553 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:44:35,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:36,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:37,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:38,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:39,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:40,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:41,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:42,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:43,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:44,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:44,573 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:44:46,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:47,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:48,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:49,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:50,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:51,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:52,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:53,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:54,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:55,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:55,593 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:44:57,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:58,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:44:59,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:00,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:01,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:02,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:03,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:04,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:05,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:06,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:06,611 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:45:08,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:09,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:10,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:11,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:12,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:13,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:14,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:15,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:16,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:17,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:17,632 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:45:19,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:20,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:21,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:22,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:23,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:24,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:25,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:26,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:27,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:28,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:28,647 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:45:30,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:31,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:32,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:33,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:34,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:35,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:36,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:37,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:38,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:39,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:39,664 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:45:41,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:42,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:43,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:44,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:45,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:46,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:47,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:48,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:49,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:50,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:50,680 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:45:52,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:53,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:54,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:55,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:56,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:57,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:58,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:45:59,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:00,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:01,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:01,699 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:03,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:04,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:05,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:06,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:07,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:08,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:09,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:10,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:11,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:12,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:12,716 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:14,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:15,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:16,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:17,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:18,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:19,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:20,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:21,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:22,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:23,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:23,726 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:25,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:26,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:27,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:28,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:29,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:30,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:31,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:32,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:33,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:34,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:34,741 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:36,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:37,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:38,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:39,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:40,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:41,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:42,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:43,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:44,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:45,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:45,759 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:47,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:48,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:49,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:50,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:51,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:52,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:53,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:54,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:55,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:56,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:56,773 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:46:58,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:46:59,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:00,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:01,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:02,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:03,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:04,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:05,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:06,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:07,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:07,788 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:47:09,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:10,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:11,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:12,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:13,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:14,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:15,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:16,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:17,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:18,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:18,802 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:47:20,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:21,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:22,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:23,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:24,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:25,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:26,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:27,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:28,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:29,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:29,815 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:47:31,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:32,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:33,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:34,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:35,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:36,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:37,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:38,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:39,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:40,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:40,829 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:47:42,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:43,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:44,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:45,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:46,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:47,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:48,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:49,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:50,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:51,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:51,843 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:47:53,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:54,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:55,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:56,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:57,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:58,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:47:59,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:00,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:01,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:02,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:02,859 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:04,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:05,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:06,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:07,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:08,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:09,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:10,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:11,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:12,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:13,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:13,878 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:15,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:16,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:17,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:18,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:19,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:20,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:21,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:22,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:23,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:24,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:24,889 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:26,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:27,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:28,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:29,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:30,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:31,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:32,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:33,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:34,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:35,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:35,906 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:37,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:38,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:39,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:40,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:41,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:42,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:43,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:44,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:45,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:46,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:46,921 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:48,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:49,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:50,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:51,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:52,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:53,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:54,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:55,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:56,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:57,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:48:57,933 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:48:59,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:00,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:01,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:02,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:03,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:04,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:05,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:06,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:07,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:08,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:08,944 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:49:10,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:11,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:12,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:13,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:14,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:15,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:16,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:17,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:18,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:19,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:19,957 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:49:21,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:22,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:23,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:24,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:25,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:26,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:27,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:28,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:29,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:30,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:30,971 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:49:32,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:33,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:34,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:35,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:36,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:37,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:38,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:39,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:40,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:41,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:41,987 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:49:43,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:44,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:45,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:46,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:47,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:48,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:49,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:50,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:51,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:52,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:53,000 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:49:55,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:56,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:57,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:58,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:49:59,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:00,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:01,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:02,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:03,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:04,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:04,011 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:50:06,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:07,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:08,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:09,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:10,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:11,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:12,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:13,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:14,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:15,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:15,023 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:50:17,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:18,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:19,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:20,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:21,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:22,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:23,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:24,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:25,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:26,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:26,037 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:50:28,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:29,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:30,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:31,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:32,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:33,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:34,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:35,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:36,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:37,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:37,051 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:50:39,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:40,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:41,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:42,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:43,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:44,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:45,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:46,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:47,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:48,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:48,061 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:50:50,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:51,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:52,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:53,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:54,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:55,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:56,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:57,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:58,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:59,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:50:59,072 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:01,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:02,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:03,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:04,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:05,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:06,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:07,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:08,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:09,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:10,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:10,081 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:12,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:13,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:14,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:15,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:16,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:17,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:18,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:19,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:20,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:21,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:21,095 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:23,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:24,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:25,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:26,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:27,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:28,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:29,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:30,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:31,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:32,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:32,105 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:34,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:35,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:36,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:37,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:38,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:39,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:40,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:41,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:42,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:43,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:43,115 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:45,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:46,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:47,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:48,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:49,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:50,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:51,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:52,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:53,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:54,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:54,125 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:51:56,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:57,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:58,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:51:59,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:00,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:01,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:02,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:03,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:04,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:05,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:05,135 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:52:07,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:08,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:09,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:10,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:11,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:12,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:13,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:14,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:15,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:16,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:16,147 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:52:18,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:19,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:20,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:21,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:22,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:23,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:24,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:25,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:26,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:27,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 08:52:27,161 INFO org.apache.hadoop.ipc.RPC: Server at localhost/127.0.0.1:9000 not available yet, Zzzzz...
2016-04-25 08:52:27,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
2016-04-25 08:53:31,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 08:53:31,960 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 08:53:31,975 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 08:53:31,977 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 08:53:31,977 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 08:53:32,215 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 08:53:32,219 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 08:53:32,310 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2016-04-25 08:53:32,628 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-sunyan/dfs/data is not formatted
2016-04-25 08:53:32,628 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2016-04-25 08:53:33,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Registered FSDatasetStatusMBean
2016-04-25 08:53:33,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened data transfer server at 50010
2016-04-25 08:53:33,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2016-04-25 08:53:33,185 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-04-25 08:53:33,243 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-04-25 08:53:33,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dfs.webhdfs.enabled = false
2016-04-25 08:53:33,257 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50075
2016-04-25 08:53:33,257 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50075 webServer.getConnectors()[0].getLocalPort() returned 50075
2016-04-25 08:53:33,257 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2016-04-25 08:53:33,257 INFO org.mortbay.log: jetty-6.1.26
2016-04-25 08:53:33,868 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2016-04-25 08:53:33,875 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2016-04-25 08:53:33,876 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source DataNode registered.
2016-04-25 08:53:34,153 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort50020 registered.
2016-04-25 08:53:34,154 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort50020 registered.
2016-04-25 08:53:34,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(myhost:50010, storageID=, infoPort=50075, ipcPort=50020)
2016-04-25 08:53:34,157 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-04-25 08:53:34,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: New storage id DS-771894789-127.0.1.1-50010-1461545614190 is assigned to data-node 127.0.0.1:50010
2016-04-25 08:53:34,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished generating blocks being written report for 1 volumes in 0 seconds
2016-04-25 08:53:34,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(127.0.0.1:50010, storageID=DS-771894789-127.0.1.1-50010-1461545614190, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/tmp/hadoop-sunyan/dfs/data/current'}
2016-04-25 08:53:34,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2016-04-25 08:53:34,251 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-04-25 08:53:34,260 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2016-04-25 08:53:34,265 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2016-04-25 08:53:34,265 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2016-04-25 08:53:34,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2016-04-25 08:53:34,266 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2016-04-25 08:53:34,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 5 msecs for RPC and NN processing
2016-04-25 08:53:34,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner
2016-04-25 08:53:34,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated rough (lockless) block report in 0 ms
2016-04-25 08:53:36,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2746851428874225169_1001 src: /127.0.0.1:59168 dest: /127.0.0.1:50010
2016-04-25 08:53:36,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59168, dest: /127.0.0.1:50010, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2746851428874225169_1001, duration: 13687705
2016-04-25 08:53:36,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2746851428874225169_1001 terminating
2016-04-25 08:58:19,353 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_-2746851428874225169_1001
2016-04-25 09:02:52,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_259746859145361668_1002 src: /127.0.0.1:59180 dest: /127.0.0.1:50010
2016-04-25 09:02:52,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59180, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_604234343_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_259746859145361668_1002, duration: 9883089
2016-04-25 09:02:52,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_259746859145361668_1002 terminating
2016-04-25 09:02:53,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8784392053591876598_1003 src: /127.0.0.1:59181 dest: /127.0.0.1:50010
2016-04-25 09:02:53,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59181, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_604234343_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8784392053591876598_1003, duration: 1330686
2016-04-25 09:02:53,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8784392053591876598_1003 terminating
2016-04-25 09:02:53,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_552743823203940094_1004 src: /127.0.0.1:59182 dest: /127.0.0.1:50010
2016-04-25 09:02:53,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59182, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_604234343_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_552743823203940094_1004, duration: 739799
2016-04-25 09:02:53,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_552743823203940094_1004 terminating
2016-04-25 09:02:53,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2762787769781678143_1005 src: /127.0.0.1:59183 dest: /127.0.0.1:50010
2016-04-25 09:02:53,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59183, dest: /127.0.0.1:50010, bytes: 33933, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_604234343_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2762787769781678143_1005, duration: 5101070
2016-04-25 09:02:53,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2762787769781678143_1005 terminating
2016-04-25 09:02:53,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1110694691513109134_1006 src: /127.0.0.1:59185 dest: /127.0.0.1:50010
2016-04-25 09:02:53,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59185, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1110694691513109134_1006, duration: 2075946
2016-04-25 09:02:53,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1110694691513109134_1006 terminating
2016-04-25 09:02:53,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3385461987428791994_1007 src: /127.0.0.1:59186 dest: /127.0.0.1:50010
2016-04-25 09:02:53,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59186, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3385461987428791994_1007, duration: 1326865
2016-04-25 09:02:53,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3385461987428791994_1007 terminating
2016-04-25 09:02:53,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59188, bytes: 34201, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1712398415_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2762787769781678143_1005, duration: 15008509
2016-04-25 09:02:53,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5033466763869055520_1009 src: /127.0.0.1:59189 dest: /127.0.0.1:50010
2016-04-25 09:02:53,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59189, dest: /127.0.0.1:50010, bytes: 48114, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1712398415_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5033466763869055520_1009, duration: 3321668
2016-04-25 09:02:53,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5033466763869055520_1009 terminating
2016-04-25 09:02:53,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59190, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1712398415_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_552743823203940094_1004, duration: 319375
2016-04-25 09:02:53,957 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59192, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3385461987428791994_1007, duration: 327477
2016-04-25 09:02:53,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59194, bytes: 34201, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-695346605_38, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2762787769781678143_1005, duration: 477559
2016-04-25 09:02:54,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59195, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-695346605_38, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_259746859145361668_1002, duration: 817576
2016-04-25 09:03:00,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5347238566961441633_1011 src: /127.0.0.1:59202 dest: /127.0.0.1:50010
2016-04-25 09:03:00,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59202, dest: /127.0.0.1:50010, bytes: 9045, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1712398415_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5347238566961441633_1011, duration: 1246584
2016-04-25 09:03:00,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5347238566961441633_1011 terminating
2016-04-25 09:03:04,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3385461987428791994_1007 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3385461987428791994 for deletion
2016-04-25 09:03:04,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2762787769781678143_1005 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2762787769781678143 for deletion
2016-04-25 09:03:04,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3385461987428791994_1007 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3385461987428791994
2016-04-25 09:03:04,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1110694691513109134_1006 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1110694691513109134 for deletion
2016-04-25 09:03:04,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2762787769781678143_1005 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2762787769781678143
2016-04-25 09:03:04,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_259746859145361668_1002 file /tmp/hadoop-sunyan/dfs/data/current/blk_259746859145361668 for deletion
2016-04-25 09:03:04,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1110694691513109134_1006 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1110694691513109134
2016-04-25 09:03:04,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_552743823203940094_1004 file /tmp/hadoop-sunyan/dfs/data/current/blk_552743823203940094 for deletion
2016-04-25 09:03:04,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_259746859145361668_1002 at file /tmp/hadoop-sunyan/dfs/data/current/blk_259746859145361668
2016-04-25 09:03:04,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8784392053591876598_1003 file /tmp/hadoop-sunyan/dfs/data/current/blk_8784392053591876598 for deletion
2016-04-25 09:03:04,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_552743823203940094_1004 at file /tmp/hadoop-sunyan/dfs/data/current/blk_552743823203940094
2016-04-25 09:03:04,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8784392053591876598_1003 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8784392053591876598
2016-04-25 09:09:40,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 1ms
2016-04-25 09:09:40,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 3 blocks took 0 msec to generate and 2 msecs for RPC and NN processing
2016-04-25 09:11:25,580 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_5033466763869055520_1009
2016-04-25 09:12:44,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-503931761135070986_1012 src: /127.0.0.1:59220 dest: /127.0.0.1:50010
2016-04-25 09:12:44,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59220, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-503931761135070986_1012, duration: 2257672
2016-04-25 09:12:44,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-503931761135070986_1012 terminating
2016-04-25 09:12:44,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6137452498988966449_1013 src: /127.0.0.1:59221 dest: /127.0.0.1:50010
2016-04-25 09:12:44,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59221, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6137452498988966449_1013, duration: 824989
2016-04-25 09:12:44,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6137452498988966449_1013 terminating
2016-04-25 09:12:44,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3734907541482649305_1014 src: /127.0.0.1:59222 dest: /127.0.0.1:50010
2016-04-25 09:12:44,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59222, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3734907541482649305_1014, duration: 755317
2016-04-25 09:12:44,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3734907541482649305_1014 terminating
2016-04-25 09:12:44,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1374636213249859857_1015 src: /127.0.0.1:59223 dest: /127.0.0.1:50010
2016-04-25 09:12:44,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59223, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1374636213249859857_1015, duration: 431298
2016-04-25 09:12:44,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1374636213249859857_1015 terminating
2016-04-25 09:12:45,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3732573816591199396_1016 src: /127.0.0.1:59225 dest: /127.0.0.1:50010
2016-04-25 09:12:45,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59225, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3732573816591199396_1016, duration: 8569162
2016-04-25 09:12:45,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3732573816591199396_1016 terminating
2016-04-25 09:12:45,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-218829648105090142_1017 src: /127.0.0.1:59226 dest: /127.0.0.1:50010
2016-04-25 09:12:45,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59226, dest: /127.0.0.1:50010, bytes: 499, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-218829648105090142_1017, duration: 703644
2016-04-25 09:12:45,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-218829648105090142_1017 terminating
2016-04-25 09:12:45,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2060207518798161520_1018 src: /127.0.0.1:59227 dest: /127.0.0.1:50010
2016-04-25 09:12:45,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59227, dest: /127.0.0.1:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2060207518798161520_1018, duration: 1731842
2016-04-25 09:12:45,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2060207518798161520_1018 terminating
2016-04-25 09:12:45,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3408140449665190530_1019 src: /127.0.0.1:59228 dest: /127.0.0.1:50010
2016-04-25 09:12:45,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59228, dest: /127.0.0.1:50010, bytes: 33938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3408140449665190530_1019, duration: 9177244
2016-04-25 09:12:45,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3408140449665190530_1019 terminating
2016-04-25 09:12:45,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6586216509140661482_1020 src: /127.0.0.1:59230 dest: /127.0.0.1:50010
2016-04-25 09:12:45,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59230, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6586216509140661482_1020, duration: 1892056
2016-04-25 09:12:45,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6586216509140661482_1020 terminating
2016-04-25 09:12:45,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4071971607593768538_1021 src: /127.0.0.1:59231 dest: /127.0.0.1:50010
2016-04-25 09:12:45,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59231, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4071971607593768538_1021, duration: 1403127
2016-04-25 09:12:45,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4071971607593768538_1021 terminating
2016-04-25 09:12:45,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59233, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2014639113_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3408140449665190530_1019, duration: 354866
2016-04-25 09:12:45,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8822945591906650127_1023 src: /127.0.0.1:59234 dest: /127.0.0.1:50010
2016-04-25 09:12:45,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59234, dest: /127.0.0.1:50010, bytes: 48091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2014639113_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8822945591906650127_1023, duration: 1803329
2016-04-25 09:12:45,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8822945591906650127_1023 terminating
2016-04-25 09:12:45,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59235, bytes: 58, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2014639113_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2060207518798161520_1018, duration: 289449
2016-04-25 09:12:45,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59237, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4071971607593768538_1021, duration: 238715
2016-04-25 09:12:45,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59239, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1985181993_67, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3408140449665190530_1019, duration: 386159
2016-04-25 09:12:45,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59240, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1985181993_67, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3732573816591199396_1016, duration: 624249
2016-04-25 09:12:49,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59246, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000001_0_-1404530356_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-218829648105090142_1017, duration: 265477
2016-04-25 09:12:49,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59248, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000001_0_-1404530356_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6137452498988966449_1013, duration: 277066
2016-04-25 09:12:49,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59249, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000000_0_-1291093779_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-218829648105090142_1017, duration: 306802
2016-04-25 09:12:49,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59250, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000000_0_-1291093779_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-503931761135070986_1012, duration: 268368
2016-04-25 09:12:52,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59256, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000002_0_555982818_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-218829648105090142_1017, duration: 284294
2016-04-25 09:12:52,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59258, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000002_0_555982818_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3734907541482649305_1014, duration: 884278
2016-04-25 09:12:52,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59259, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000003_0_1096140411_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-218829648105090142_1017, duration: 255629
2016-04-25 09:12:52,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59260, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0002_m_000003_0_1096140411_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1374636213249859857_1015, duration: 302504
2016-04-25 09:12:58,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6961789502745928765_1025 src: /127.0.0.1:59262 dest: /127.0.0.1:50010
2016-04-25 09:12:58,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59262, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0002_r_000000_0_1902952171_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6961789502745928765_1025, duration: 2102296
2016-04-25 09:12:58,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6961789502745928765_1025 terminating
2016-04-25 09:12:58,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4440790340266132248_1025 src: /127.0.0.1:59263 dest: /127.0.0.1:50010
2016-04-25 09:12:58,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59263, dest: /127.0.0.1:50010, bytes: 97, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0002_r_000000_0_1902952171_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4440790340266132248_1025, duration: 668612
2016-04-25 09:12:58,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4440790340266132248_1025 terminating
2016-04-25 09:13:01,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3585703583677147153_1026 src: /127.0.0.1:59267 dest: /127.0.0.1:50010
2016-04-25 09:13:01,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59267, dest: /127.0.0.1:50010, bytes: 22059, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2014639113_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3585703583677147153_1026, duration: 1154411
2016-04-25 09:13:01,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3585703583677147153_1026 terminating
2016-04-25 09:13:01,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59270, bytes: 122, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_338801672_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6961789502745928765_1025, duration: 251575
2016-04-25 09:13:04,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8822945591906650127_1023 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8822945591906650127 for deletion
2016-04-25 09:13:04,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6961789502745928765_1025 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6961789502745928765 for deletion
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8822945591906650127_1023 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8822945591906650127
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6586216509140661482_1020 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6586216509140661482 for deletion
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6961789502745928765_1025 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6961789502745928765
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4440790340266132248_1025 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4440790340266132248 for deletion
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6586216509140661482_1020 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6586216509140661482
2016-04-25 09:13:04,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4071971607593768538_1021 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4071971607593768538 for deletion
2016-04-25 09:13:04,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4440790340266132248_1025 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4440790340266132248
2016-04-25 09:13:04,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3585703583677147153_1026 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3585703583677147153 for deletion
2016-04-25 09:13:04,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4071971607593768538_1021 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4071971607593768538
2016-04-25 09:13:04,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-503931761135070986_1012 file /tmp/hadoop-sunyan/dfs/data/current/blk_-503931761135070986 for deletion
2016-04-25 09:13:04,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3585703583677147153_1026 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3585703583677147153
2016-04-25 09:13:04,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-218829648105090142_1017 file /tmp/hadoop-sunyan/dfs/data/current/blk_-218829648105090142 for deletion
2016-04-25 09:13:04,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-503931761135070986_1012 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-503931761135070986
2016-04-25 09:13:04,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1374636213249859857_1015 file /tmp/hadoop-sunyan/dfs/data/current/blk_1374636213249859857 for deletion
2016-04-25 09:13:04,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-218829648105090142_1017 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-218829648105090142
2016-04-25 09:13:04,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2060207518798161520_1018 file /tmp/hadoop-sunyan/dfs/data/current/blk_2060207518798161520 for deletion
2016-04-25 09:13:04,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1374636213249859857_1015 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1374636213249859857
2016-04-25 09:13:04,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3408140449665190530_1019 file /tmp/hadoop-sunyan/dfs/data/current/blk_3408140449665190530 for deletion
2016-04-25 09:13:04,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2060207518798161520_1018 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2060207518798161520
2016-04-25 09:13:04,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3732573816591199396_1016 file /tmp/hadoop-sunyan/dfs/data/current/blk_3732573816591199396 for deletion
2016-04-25 09:13:04,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3408140449665190530_1019 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3408140449665190530
2016-04-25 09:13:04,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3734907541482649305_1014 file /tmp/hadoop-sunyan/dfs/data/current/blk_3734907541482649305 for deletion
2016-04-25 09:13:04,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3732573816591199396_1016 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3732573816591199396
2016-04-25 09:13:04,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6137452498988966449_1013 file /tmp/hadoop-sunyan/dfs/data/current/blk_6137452498988966449 for deletion
2016-04-25 09:13:04,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3734907541482649305_1014 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3734907541482649305
2016-04-25 09:13:04,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6137452498988966449_1013 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6137452498988966449
2016-04-25 09:16:51,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-81016501517888341_1027 src: /127.0.0.1:59276 dest: /127.0.0.1:50010
2016-04-25 09:16:51,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59276, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129126534_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-81016501517888341_1027, duration: 4237972
2016-04-25 09:16:51,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-81016501517888341_1027 terminating
2016-04-25 09:16:51,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1372629498830365304_1028 src: /127.0.0.1:59277 dest: /127.0.0.1:50010
2016-04-25 09:16:51,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59277, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129126534_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1372629498830365304_1028, duration: 614918
2016-04-25 09:16:51,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1372629498830365304_1028 terminating
2016-04-25 09:16:51,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5770745820436421947_1029 src: /127.0.0.1:59278 dest: /127.0.0.1:50010
2016-04-25 09:16:51,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59278, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129126534_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5770745820436421947_1029, duration: 1206635
2016-04-25 09:16:51,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5770745820436421947_1029 terminating
2016-04-25 09:16:51,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1974923023462058580_1030 src: /127.0.0.1:59279 dest: /127.0.0.1:50010
2016-04-25 09:16:51,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59279, dest: /127.0.0.1:50010, bytes: 34005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129126534_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1974923023462058580_1030, duration: 1249951
2016-04-25 09:16:51,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1974923023462058580_1030 terminating
2016-04-25 09:16:51,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6960336673201280176_1031 src: /127.0.0.1:59281 dest: /127.0.0.1:50010
2016-04-25 09:16:51,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59281, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6960336673201280176_1031, duration: 1643209
2016-04-25 09:16:51,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6960336673201280176_1031 terminating
2016-04-25 09:16:51,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-993075820555456791_1032 src: /127.0.0.1:59282 dest: /127.0.0.1:50010
2016-04-25 09:16:51,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59282, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-993075820555456791_1032, duration: 681851
2016-04-25 09:16:51,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-993075820555456791_1032 terminating
2016-04-25 09:16:51,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59284, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1646706972_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1974923023462058580_1030, duration: 370081
2016-04-25 09:16:51,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7383289974231899702_1034 src: /127.0.0.1:59285 dest: /127.0.0.1:50010
2016-04-25 09:16:51,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59285, dest: /127.0.0.1:50010, bytes: 48186, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1646706972_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7383289974231899702_1034, duration: 1228263
2016-04-25 09:16:51,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7383289974231899702_1034 terminating
2016-04-25 09:16:51,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59286, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1646706972_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5770745820436421947_1029, duration: 249112
2016-04-25 09:16:52,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59288, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-993075820555456791_1032, duration: 566985
2016-04-25 09:16:52,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59290, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-743149269_136, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1974923023462058580_1030, duration: 684916
2016-04-25 09:16:52,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59291, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-743149269_136, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-81016501517888341_1027, duration: 673841
2016-04-25 09:16:56,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3862301484984433329_1035 src: /127.0.0.1:59296 dest: /127.0.0.1:50010
2016-04-25 09:16:56,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59296, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0003_r_000000_0_1496996755_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3862301484984433329_1035, duration: 5778576
2016-04-25 09:16:56,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3862301484984433329_1035 terminating
2016-04-25 09:16:58,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1478809391415815336_1036 src: /127.0.0.1:59299 dest: /127.0.0.1:50010
2016-04-25 09:16:58,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59299, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1646706972_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1478809391415815336_1036, duration: 1276940
2016-04-25 09:16:58,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1478809391415815336_1036 terminating
2016-04-25 09:16:59,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1537202614896923165_1037 src: /127.0.0.1:59300 dest: /127.0.0.1:50010
2016-04-25 09:16:59,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59300, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129126534_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1537202614896923165_1037, duration: 6713110
2016-04-25 09:16:59,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1537202614896923165_1037 terminating
2016-04-25 09:17:01,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3862301484984433329_1035 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3862301484984433329 for deletion
2016-04-25 09:17:01,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1478809391415815336_1036 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1478809391415815336 for deletion
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3862301484984433329_1035 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3862301484984433329
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1372629498830365304_1028 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1372629498830365304 for deletion
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1478809391415815336_1036 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1478809391415815336
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1372629498830365304_1028 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1372629498830365304
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-993075820555456791_1032 file /tmp/hadoop-sunyan/dfs/data/current/blk_-993075820555456791 for deletion
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-81016501517888341_1027 file /tmp/hadoop-sunyan/dfs/data/current/blk_-81016501517888341 for deletion
2016-04-25 09:17:01,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-993075820555456791_1032 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-993075820555456791
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1974923023462058580_1030 file /tmp/hadoop-sunyan/dfs/data/current/blk_1974923023462058580 for deletion
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-81016501517888341_1027 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-81016501517888341
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5770745820436421947_1029 file /tmp/hadoop-sunyan/dfs/data/current/blk_5770745820436421947 for deletion
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1974923023462058580_1030 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1974923023462058580
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5770745820436421947_1029 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5770745820436421947
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6960336673201280176_1031 file /tmp/hadoop-sunyan/dfs/data/current/blk_6960336673201280176 for deletion
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7383289974231899702_1034 file /tmp/hadoop-sunyan/dfs/data/current/blk_7383289974231899702 for deletion
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6960336673201280176_1031 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6960336673201280176
2016-04-25 09:17:01,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7383289974231899702_1034 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7383289974231899702
2016-04-25 09:19:16,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7549608687029410432_1038 src: /127.0.0.1:59304 dest: /127.0.0.1:50010
2016-04-25 09:19:16,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59304, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_977133232_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7549608687029410432_1038, duration: 6054182
2016-04-25 09:19:16,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7549608687029410432_1038 terminating
2016-04-25 09:19:16,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4854399979959883389_1039 src: /127.0.0.1:59305 dest: /127.0.0.1:50010
2016-04-25 09:19:16,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59305, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_977133232_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4854399979959883389_1039, duration: 696151
2016-04-25 09:19:16,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4854399979959883389_1039 terminating
2016-04-25 09:19:16,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2409334649255072702_1040 src: /127.0.0.1:59306 dest: /127.0.0.1:50010
2016-04-25 09:19:16,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59306, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_977133232_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2409334649255072702_1040, duration: 848911
2016-04-25 09:19:16,674 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2409334649255072702_1040 terminating
2016-04-25 09:19:16,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1303861662113402923_1041 src: /127.0.0.1:59307 dest: /127.0.0.1:50010
2016-04-25 09:19:16,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59307, dest: /127.0.0.1:50010, bytes: 34005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_977133232_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1303861662113402923_1041, duration: 2697683
2016-04-25 09:19:16,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1303861662113402923_1041 terminating
2016-04-25 09:19:16,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_244765355937315016_1042 src: /127.0.0.1:59309 dest: /127.0.0.1:50010
2016-04-25 09:19:16,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59309, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_244765355937315016_1042, duration: 1024074
2016-04-25 09:19:16,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_244765355937315016_1042 terminating
2016-04-25 09:19:16,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3027016113864911582_1043 src: /127.0.0.1:59310 dest: /127.0.0.1:50010
2016-04-25 09:19:16,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59310, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3027016113864911582_1043, duration: 803701
2016-04-25 09:19:16,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3027016113864911582_1043 terminating
2016-04-25 09:19:16,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59312, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1765534635_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1303861662113402923_1041, duration: 253042
2016-04-25 09:19:16,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1240028726360263359_1045 src: /127.0.0.1:59313 dest: /127.0.0.1:50010
2016-04-25 09:19:16,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59313, dest: /127.0.0.1:50010, bytes: 48186, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1765534635_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1240028726360263359_1045, duration: 1011798
2016-04-25 09:19:16,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1240028726360263359_1045 terminating
2016-04-25 09:19:16,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59314, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1765534635_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2409334649255072702_1040, duration: 199513
2016-04-25 09:19:17,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59316, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3027016113864911582_1043, duration: 483039
2016-04-25 09:19:17,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59318, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_957349864_165, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1303861662113402923_1041, duration: 576344
2016-04-25 09:19:17,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59319, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_957349864_165, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7549608687029410432_1038, duration: 799221
2016-04-25 09:19:20,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1039645269521233405_1046 src: /127.0.0.1:59324 dest: /127.0.0.1:50010
2016-04-25 09:19:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59324, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0005_r_000000_0_-1646955965_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1039645269521233405_1046, duration: 2996865
2016-04-25 09:19:20,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1039645269521233405_1046 terminating
2016-04-25 09:19:23,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1693849937604606526_1047 src: /127.0.0.1:59327 dest: /127.0.0.1:50010
2016-04-25 09:19:23,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59327, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1765534635_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1693849937604606526_1047, duration: 877800
2016-04-25 09:19:23,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1693849937604606526_1047 terminating
2016-04-25 09:19:24,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7862356526682066269_1048 src: /127.0.0.1:59328 dest: /127.0.0.1:50010
2016-04-25 09:19:24,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59328, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_977133232_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7862356526682066269_1048, duration: 2560796
2016-04-25 09:19:24,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7862356526682066269_1048 terminating
2016-04-25 09:19:25,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-7549608687029410432_1038 file /tmp/hadoop-sunyan/dfs/data/current/blk_-7549608687029410432 for deletion
2016-04-25 09:19:25,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3027016113864911582_1043 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3027016113864911582 for deletion
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1303861662113402923_1041 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1303861662113402923 for deletion
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-7549608687029410432_1038 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-7549608687029410432
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1240028726360263359_1045 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1240028726360263359 for deletion
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3027016113864911582_1043 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3027016113864911582
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1039645269521233405_1046 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1039645269521233405 for deletion
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1303861662113402923_1041 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1303861662113402923
2016-04-25 09:19:25,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_244765355937315016_1042 file /tmp/hadoop-sunyan/dfs/data/current/blk_244765355937315016 for deletion
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1240028726360263359_1045 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1240028726360263359
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1039645269521233405_1046 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1039645269521233405
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1693849937604606526_1047 file /tmp/hadoop-sunyan/dfs/data/current/blk_1693849937604606526 for deletion
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_244765355937315016_1042 at file /tmp/hadoop-sunyan/dfs/data/current/blk_244765355937315016
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1693849937604606526_1047 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1693849937604606526
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2409334649255072702_1040 file /tmp/hadoop-sunyan/dfs/data/current/blk_2409334649255072702 for deletion
2016-04-25 09:19:25,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4854399979959883389_1039 file /tmp/hadoop-sunyan/dfs/data/current/blk_4854399979959883389 for deletion
2016-04-25 09:19:25,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2409334649255072702_1040 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2409334649255072702
2016-04-25 09:19:25,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4854399979959883389_1039 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4854399979959883389
2016-04-25 09:19:41,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1523956143033812987_1049 src: /127.0.0.1:59331 dest: /127.0.0.1:50010
2016-04-25 09:19:41,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59331, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1735261844_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1523956143033812987_1049, duration: 4357396
2016-04-25 09:19:41,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1523956143033812987_1049 terminating
2016-04-25 09:19:41,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_9101192440216005143_1050 src: /127.0.0.1:59332 dest: /127.0.0.1:50010
2016-04-25 09:19:41,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59332, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1735261844_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9101192440216005143_1050, duration: 1048167
2016-04-25 09:19:41,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_9101192440216005143_1050 terminating
2016-04-25 09:19:41,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7051282957775664407_1051 src: /127.0.0.1:59333 dest: /127.0.0.1:50010
2016-04-25 09:19:41,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59333, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1735261844_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7051282957775664407_1051, duration: 819286
2016-04-25 09:19:41,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7051282957775664407_1051 terminating
2016-04-25 09:19:41,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_456286294647331593_1052 src: /127.0.0.1:59334 dest: /127.0.0.1:50010
2016-04-25 09:19:41,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59334, dest: /127.0.0.1:50010, bytes: 34005, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1735261844_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_456286294647331593_1052, duration: 5640117
2016-04-25 09:19:41,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_456286294647331593_1052 terminating
2016-04-25 09:19:41,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_830881930460287344_1053 src: /127.0.0.1:59336 dest: /127.0.0.1:50010
2016-04-25 09:19:41,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59336, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_830881930460287344_1053, duration: 905647
2016-04-25 09:19:41,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_830881930460287344_1053 terminating
2016-04-25 09:19:41,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-355961513377628517_1054 src: /127.0.0.1:59337 dest: /127.0.0.1:50010
2016-04-25 09:19:41,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59337, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-355961513377628517_1054, duration: 1921029
2016-04-25 09:19:41,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-355961513377628517_1054 terminating
2016-04-25 09:19:41,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59339, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-402249732_31, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_456286294647331593_1052, duration: 414976
2016-04-25 09:19:41,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6909064935640647156_1056 src: /127.0.0.1:59340 dest: /127.0.0.1:50010
2016-04-25 09:19:41,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59340, dest: /127.0.0.1:50010, bytes: 48186, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-402249732_31, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6909064935640647156_1056, duration: 967075
2016-04-25 09:19:41,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6909064935640647156_1056 terminating
2016-04-25 09:19:41,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59341, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-402249732_31, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7051282957775664407_1051, duration: 267571
2016-04-25 09:19:41,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59343, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-355961513377628517_1054, duration: 266112
2016-04-25 09:19:41,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59345, bytes: 34273, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2027075510_194, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_456286294647331593_1052, duration: 242239
2016-04-25 09:19:41,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59346, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2027075510_194, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1523956143033812987_1049, duration: 548493
2016-04-25 09:19:45,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7075602709833966981_1057 src: /127.0.0.1:59351 dest: /127.0.0.1:50010
2016-04-25 09:19:45,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59351, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0007_r_000000_0_-818308066_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7075602709833966981_1057, duration: 5077596
2016-04-25 09:19:45,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7075602709833966981_1057 terminating
2016-04-25 09:19:48,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2665297651823808685_1058 src: /127.0.0.1:59354 dest: /127.0.0.1:50010
2016-04-25 09:19:48,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59354, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-402249732_31, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2665297651823808685_1058, duration: 2153092
2016-04-25 09:19:48,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2665297651823808685_1058 terminating
2016-04-25 09:19:48,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3362722174012051584_1059 src: /127.0.0.1:59355 dest: /127.0.0.1:50010
2016-04-25 09:19:48,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59355, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1735261844_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3362722174012051584_1059, duration: 4123601
2016-04-25 09:19:48,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3362722174012051584_1059 terminating
2016-04-25 09:19:49,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6909064935640647156_1056 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6909064935640647156 for deletion
2016-04-25 09:19:49,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1523956143033812987_1049 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1523956143033812987 for deletion
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6909064935640647156_1056 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6909064935640647156
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-355961513377628517_1054 file /tmp/hadoop-sunyan/dfs/data/current/blk_-355961513377628517 for deletion
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_456286294647331593_1052 file /tmp/hadoop-sunyan/dfs/data/current/blk_456286294647331593 for deletion
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1523956143033812987_1049 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1523956143033812987
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_830881930460287344_1053 file /tmp/hadoop-sunyan/dfs/data/current/blk_830881930460287344 for deletion
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-355961513377628517_1054 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-355961513377628517
2016-04-25 09:19:49,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2665297651823808685_1058 file /tmp/hadoop-sunyan/dfs/data/current/blk_2665297651823808685 for deletion
2016-04-25 09:19:49,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_456286294647331593_1052 at file /tmp/hadoop-sunyan/dfs/data/current/blk_456286294647331593
2016-04-25 09:19:49,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7051282957775664407_1051 file /tmp/hadoop-sunyan/dfs/data/current/blk_7051282957775664407 for deletion
2016-04-25 09:19:49,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_830881930460287344_1053 at file /tmp/hadoop-sunyan/dfs/data/current/blk_830881930460287344
2016-04-25 09:19:49,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7075602709833966981_1057 file /tmp/hadoop-sunyan/dfs/data/current/blk_7075602709833966981 for deletion
2016-04-25 09:19:49,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2665297651823808685_1058 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2665297651823808685
2016-04-25 09:19:49,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_9101192440216005143_1050 file /tmp/hadoop-sunyan/dfs/data/current/blk_9101192440216005143 for deletion
2016-04-25 09:19:49,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7051282957775664407_1051 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7051282957775664407
2016-04-25 09:19:49,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7075602709833966981_1057 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7075602709833966981
2016-04-25 09:19:49,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_9101192440216005143_1050 at file /tmp/hadoop-sunyan/dfs/data/current/blk_9101192440216005143
2016-04-25 09:23:33,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5553740759281267749_1060 src: /127.0.0.1:59360 dest: /127.0.0.1:50010
2016-04-25 09:23:33,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59360, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_379402670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5553740759281267749_1060, duration: 7175606
2016-04-25 09:23:33,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5553740759281267749_1060 terminating
2016-04-25 09:23:34,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5169924243096824602_1061 src: /127.0.0.1:59361 dest: /127.0.0.1:50010
2016-04-25 09:23:34,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59361, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_379402670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5169924243096824602_1061, duration: 773653
2016-04-25 09:23:34,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5169924243096824602_1061 terminating
2016-04-25 09:23:34,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-900574447374478548_1062 src: /127.0.0.1:59362 dest: /127.0.0.1:50010
2016-04-25 09:23:34,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59362, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_379402670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-900574447374478548_1062, duration: 528037
2016-04-25 09:23:34,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-900574447374478548_1062 terminating
2016-04-25 09:23:34,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5472627038431172967_1063 src: /127.0.0.1:59363 dest: /127.0.0.1:50010
2016-04-25 09:23:34,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59363, dest: /127.0.0.1:50010, bytes: 34006, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_379402670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5472627038431172967_1063, duration: 3161430
2016-04-25 09:23:34,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5472627038431172967_1063 terminating
2016-04-25 09:23:34,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6968316542246413371_1064 src: /127.0.0.1:59365 dest: /127.0.0.1:50010
2016-04-25 09:23:34,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59365, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6968316542246413371_1064, duration: 491001
2016-04-25 09:23:34,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6968316542246413371_1064 terminating
2016-04-25 09:23:34,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2400695455185872932_1065 src: /127.0.0.1:59366 dest: /127.0.0.1:50010
2016-04-25 09:23:34,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59366, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2400695455185872932_1065, duration: 824673
2016-04-25 09:23:34,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2400695455185872932_1065 terminating
2016-04-25 09:23:34,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59368, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_988701197_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5472627038431172967_1063, duration: 378134
2016-04-25 09:23:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4256395240627210528_1067 src: /127.0.0.1:59369 dest: /127.0.0.1:50010
2016-04-25 09:23:34,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59369, dest: /127.0.0.1:50010, bytes: 48187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_988701197_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4256395240627210528_1067, duration: 943359
2016-04-25 09:23:34,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4256395240627210528_1067 terminating
2016-04-25 09:23:34,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59370, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_988701197_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-900574447374478548_1062, duration: 189487
2016-04-25 09:23:34,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59372, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2400695455185872932_1065, duration: 549400
2016-04-25 09:23:34,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59374, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1573782989_221, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5472627038431172967_1063, duration: 648266
2016-04-25 09:23:34,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59375, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1573782989_221, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5553740759281267749_1060, duration: 951288
2016-04-25 09:23:38,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_158727166816249889_1068 src: /127.0.0.1:59381 dest: /127.0.0.1:50010
2016-04-25 09:23:38,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59381, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0009_r_000000_0_1583776272_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_158727166816249889_1068, duration: 11766739
2016-04-25 09:23:38,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_158727166816249889_1068 terminating
2016-04-25 09:23:41,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2806880738787939854_1069 src: /127.0.0.1:59384 dest: /127.0.0.1:50010
2016-04-25 09:23:41,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59384, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_988701197_29, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2806880738787939854_1069, duration: 2771091
2016-04-25 09:23:41,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2806880738787939854_1069 terminating
2016-04-25 09:23:41,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1209927743187368665_1070 src: /127.0.0.1:59385 dest: /127.0.0.1:50010
2016-04-25 09:23:41,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59385, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_379402670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1209927743187368665_1070, duration: 2998314
2016-04-25 09:23:41,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1209927743187368665_1070 terminating
2016-04-25 09:23:43,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6968316542246413371_1064 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6968316542246413371 for deletion
2016-04-25 09:23:43,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5553740759281267749_1060 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5553740759281267749 for deletion
2016-04-25 09:23:43,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6968316542246413371_1064 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6968316542246413371
2016-04-25 09:23:43,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5472627038431172967_1063 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5472627038431172967 for deletion
2016-04-25 09:23:43,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5553740759281267749_1060 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5553740759281267749
2016-04-25 09:23:43,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5169924243096824602_1061 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5169924243096824602 for deletion
2016-04-25 09:23:43,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5472627038431172967_1063 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5472627038431172967
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-900574447374478548_1062 file /tmp/hadoop-sunyan/dfs/data/current/blk_-900574447374478548 for deletion
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5169924243096824602_1061 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5169924243096824602
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_158727166816249889_1068 file /tmp/hadoop-sunyan/dfs/data/current/blk_158727166816249889 for deletion
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-900574447374478548_1062 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-900574447374478548
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2400695455185872932_1065 file /tmp/hadoop-sunyan/dfs/data/current/blk_2400695455185872932 for deletion
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_158727166816249889_1068 at file /tmp/hadoop-sunyan/dfs/data/current/blk_158727166816249889
2016-04-25 09:23:43,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2806880738787939854_1069 file /tmp/hadoop-sunyan/dfs/data/current/blk_2806880738787939854 for deletion
2016-04-25 09:23:43,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2400695455185872932_1065 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2400695455185872932
2016-04-25 09:23:43,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4256395240627210528_1067 file /tmp/hadoop-sunyan/dfs/data/current/blk_4256395240627210528 for deletion
2016-04-25 09:23:43,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2806880738787939854_1069 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2806880738787939854
2016-04-25 09:23:43,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4256395240627210528_1067 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4256395240627210528
2016-04-25 09:33:13,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4795215082321901057_1071 src: /127.0.0.1:59391 dest: /127.0.0.1:50010
2016-04-25 09:33:13,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59391, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840248119_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4795215082321901057_1071, duration: 5435525
2016-04-25 09:33:13,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4795215082321901057_1071 terminating
2016-04-25 09:33:13,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7677160819971982543_1072 src: /127.0.0.1:59392 dest: /127.0.0.1:50010
2016-04-25 09:33:13,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59392, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840248119_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7677160819971982543_1072, duration: 716093
2016-04-25 09:33:13,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7677160819971982543_1072 terminating
2016-04-25 09:33:13,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3893537429436645759_1073 src: /127.0.0.1:59393 dest: /127.0.0.1:50010
2016-04-25 09:33:14,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59393, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840248119_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3893537429436645759_1073, duration: 1266299
2016-04-25 09:33:14,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3893537429436645759_1073 terminating
2016-04-25 09:33:14,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6943937206302263869_1074 src: /127.0.0.1:59394 dest: /127.0.0.1:50010
2016-04-25 09:33:14,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59394, dest: /127.0.0.1:50010, bytes: 34006, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840248119_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6943937206302263869_1074, duration: 3489023
2016-04-25 09:33:14,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6943937206302263869_1074 terminating
2016-04-25 09:33:14,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7252509671676688646_1075 src: /127.0.0.1:59396 dest: /127.0.0.1:50010
2016-04-25 09:33:14,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59396, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7252509671676688646_1075, duration: 2313566
2016-04-25 09:33:14,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7252509671676688646_1075 terminating
2016-04-25 09:33:14,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5502327609123365451_1076 src: /127.0.0.1:59397 dest: /127.0.0.1:50010
2016-04-25 09:33:14,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59397, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5502327609123365451_1076, duration: 702835
2016-04-25 09:33:14,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5502327609123365451_1076 terminating
2016-04-25 09:33:14,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59399, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1074733279_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6943937206302263869_1074, duration: 243401
2016-04-25 09:33:14,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3836008992486382825_1078 src: /127.0.0.1:59400 dest: /127.0.0.1:50010
2016-04-25 09:33:14,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59400, dest: /127.0.0.1:50010, bytes: 48187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1074733279_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3836008992486382825_1078, duration: 1119751
2016-04-25 09:33:14,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3836008992486382825_1078 terminating
2016-04-25 09:33:14,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59401, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1074733279_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3893537429436645759_1073, duration: 284002
2016-04-25 09:33:14,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59403, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5502327609123365451_1076, duration: 406846
2016-04-25 09:33:14,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59405, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-324479215_250, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6943937206302263869_1074, duration: 398410
2016-04-25 09:33:14,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59406, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-324479215_250, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4795215082321901057_1071, duration: 579389
2016-04-25 09:33:18,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5536628157641936708_1079 src: /127.0.0.1:59411 dest: /127.0.0.1:50010
2016-04-25 09:33:18,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59411, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0011_r_000000_0_1723912428_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5536628157641936708_1079, duration: 2777809
2016-04-25 09:33:18,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5536628157641936708_1079 terminating
2016-04-25 09:33:21,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_360546294512368051_1080 src: /127.0.0.1:59414 dest: /127.0.0.1:50010
2016-04-25 09:33:21,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59414, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1074733279_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_360546294512368051_1080, duration: 3703090
2016-04-25 09:33:21,142 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_360546294512368051_1080 terminating
2016-04-25 09:33:21,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5104713727101707218_1081 src: /127.0.0.1:59415 dest: /127.0.0.1:50010
2016-04-25 09:33:21,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59415, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840248119_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5104713727101707218_1081, duration: 4196880
2016-04-25 09:33:21,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5104713727101707218_1081 terminating
2016-04-25 09:33:23,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-7677160819971982543_1072 file /tmp/hadoop-sunyan/dfs/data/current/blk_-7677160819971982543 for deletion
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6943937206302263869_1074 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6943937206302263869 for deletion
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4795215082321901057_1071 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4795215082321901057 for deletion
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-7677160819971982543_1072 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-7677160819971982543
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3893537429436645759_1073 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3893537429436645759 for deletion
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6943937206302263869_1074 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6943937206302263869
2016-04-25 09:33:23,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_360546294512368051_1080 file /tmp/hadoop-sunyan/dfs/data/current/blk_360546294512368051 for deletion
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4795215082321901057_1071 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4795215082321901057
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3836008992486382825_1078 file /tmp/hadoop-sunyan/dfs/data/current/blk_3836008992486382825 for deletion
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3893537429436645759_1073 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3893537429436645759
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5502327609123365451_1076 file /tmp/hadoop-sunyan/dfs/data/current/blk_5502327609123365451 for deletion
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_360546294512368051_1080 at file /tmp/hadoop-sunyan/dfs/data/current/blk_360546294512368051
2016-04-25 09:33:23,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5536628157641936708_1079 file /tmp/hadoop-sunyan/dfs/data/current/blk_5536628157641936708 for deletion
2016-04-25 09:33:23,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3836008992486382825_1078 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3836008992486382825
2016-04-25 09:33:23,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7252509671676688646_1075 file /tmp/hadoop-sunyan/dfs/data/current/blk_7252509671676688646 for deletion
2016-04-25 09:33:23,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5502327609123365451_1076 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5502327609123365451
2016-04-25 09:33:23,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5536628157641936708_1079 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5536628157641936708
2016-04-25 09:33:23,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7252509671676688646_1075 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7252509671676688646
2016-04-25 09:33:58,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4231783964767467929_1082 src: /127.0.0.1:59418 dest: /127.0.0.1:50010
2016-04-25 09:33:58,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59418, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4231783964767467929_1082, duration: 1911831
2016-04-25 09:33:58,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4231783964767467929_1082 terminating
2016-04-25 09:33:59,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8296171053702472734_1083 src: /127.0.0.1:59419 dest: /127.0.0.1:50010
2016-04-25 09:33:59,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59419, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8296171053702472734_1083, duration: 1165022
2016-04-25 09:33:59,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8296171053702472734_1083 terminating
2016-04-25 09:33:59,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8685839914547727287_1084 src: /127.0.0.1:59420 dest: /127.0.0.1:50010
2016-04-25 09:33:59,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59420, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8685839914547727287_1084, duration: 1039257
2016-04-25 09:33:59,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8685839914547727287_1084 terminating
2016-04-25 09:33:59,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1954666784571810447_1085 src: /127.0.0.1:59421 dest: /127.0.0.1:50010
2016-04-25 09:33:59,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59421, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1954666784571810447_1085, duration: 731475
2016-04-25 09:33:59,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1954666784571810447_1085 terminating
2016-04-25 09:33:59,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8181551804054923749_1086 src: /127.0.0.1:59423 dest: /127.0.0.1:50010
2016-04-25 09:33:59,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59423, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8181551804054923749_1086, duration: 2209324
2016-04-25 09:33:59,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8181551804054923749_1086 terminating
2016-04-25 09:33:59,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8882698119231885625_1087 src: /127.0.0.1:59424 dest: /127.0.0.1:50010
2016-04-25 09:33:59,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59424, dest: /127.0.0.1:50010, bytes: 499, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8882698119231885625_1087, duration: 654692
2016-04-25 09:33:59,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8882698119231885625_1087 terminating
2016-04-25 09:33:59,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2424889144869988943_1088 src: /127.0.0.1:59425 dest: /127.0.0.1:50010
2016-04-25 09:33:59,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59425, dest: /127.0.0.1:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2424889144869988943_1088, duration: 1022326
2016-04-25 09:33:59,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2424889144869988943_1088 terminating
2016-04-25 09:33:59,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4632684579053209134_1089 src: /127.0.0.1:59426 dest: /127.0.0.1:50010
2016-04-25 09:33:59,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59426, dest: /127.0.0.1:50010, bytes: 33938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4632684579053209134_1089, duration: 10194992
2016-04-25 09:33:59,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4632684579053209134_1089 terminating
2016-04-25 09:33:59,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8851906794908078937_1090 src: /127.0.0.1:59428 dest: /127.0.0.1:50010
2016-04-25 09:33:59,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59428, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8851906794908078937_1090, duration: 737626
2016-04-25 09:33:59,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8851906794908078937_1090 terminating
2016-04-25 09:33:59,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8685501273118886465_1091 src: /127.0.0.1:59429 dest: /127.0.0.1:50010
2016-04-25 09:33:59,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59429, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8685501273118886465_1091, duration: 640223
2016-04-25 09:33:59,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8685501273118886465_1091 terminating
2016-04-25 09:33:59,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59431, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-576424807_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4632684579053209134_1089, duration: 361241
2016-04-25 09:33:59,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_9139367798057818897_1093 src: /127.0.0.1:59432 dest: /127.0.0.1:50010
2016-04-25 09:33:59,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59432, dest: /127.0.0.1:50010, bytes: 48091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576424807_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9139367798057818897_1093, duration: 2736320
2016-04-25 09:33:59,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_9139367798057818897_1093 terminating
2016-04-25 09:34:00,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59433, bytes: 58, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-576424807_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2424889144869988943_1088, duration: 254222
2016-04-25 09:34:00,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59435, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8685501273118886465_1091, duration: 173049
2016-04-25 09:34:00,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59437, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_759338422_279, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4632684579053209134_1089, duration: 406661
2016-04-25 09:34:00,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59438, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_759338422_279, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8181551804054923749_1086, duration: 442890
2016-04-25 09:34:03,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59445, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000001_0_-842741862_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8882698119231885625_1087, duration: 243994
2016-04-25 09:34:04,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59446, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000001_0_-842741862_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8296171053702472734_1083, duration: 246195
2016-04-25 09:34:04,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59447, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000000_0_-1477147481_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8882698119231885625_1087, duration: 226588
2016-04-25 09:34:04,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59448, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000000_0_-1477147481_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4231783964767467929_1082, duration: 257696
2016-04-25 09:34:07,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59455, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000003_0_768242171_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8882698119231885625_1087, duration: 256421
2016-04-25 09:34:07,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59456, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000003_0_768242171_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1954666784571810447_1085, duration: 239145
2016-04-25 09:34:07,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59457, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000002_0_46941676_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8882698119231885625_1087, duration: 231069
2016-04-25 09:34:07,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59458, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0013_m_000002_0_46941676_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8685839914547727287_1084, duration: 242877
2016-04-25 09:34:13,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8427579820924570690_1095 src: /127.0.0.1:59460 dest: /127.0.0.1:50010
2016-04-25 09:34:13,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59460, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0013_r_000000_0_1287164775_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8427579820924570690_1095, duration: 2681950
2016-04-25 09:34:13,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8427579820924570690_1095 terminating
2016-04-25 09:34:13,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_897857511034492603_1095 src: /127.0.0.1:59461 dest: /127.0.0.1:50010
2016-04-25 09:34:13,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59461, dest: /127.0.0.1:50010, bytes: 97, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0013_r_000000_0_1287164775_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_897857511034492603_1095, duration: 643276
2016-04-25 09:34:13,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_897857511034492603_1095 terminating
2016-04-25 09:34:16,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3976966448601259965_1096 src: /127.0.0.1:59465 dest: /127.0.0.1:50010
2016-04-25 09:34:16,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59465, dest: /127.0.0.1:50010, bytes: 22062, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-576424807_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3976966448601259965_1096, duration: 8425745
2016-04-25 09:34:16,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3976966448601259965_1096 terminating
2016-04-25 09:34:17,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59468, bytes: 122, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_992266438_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8427579820924570690_1095, duration: 276077
2016-04-25 09:34:20,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8882698119231885625_1087 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8882698119231885625 for deletion
2016-04-25 09:34:20,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8851906794908078937_1090 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8851906794908078937 for deletion
2016-04-25 09:34:20,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8685839914547727287_1084 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8685839914547727287 for deletion
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8882698119231885625_1087 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8882698119231885625
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8427579820924570690_1095 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8427579820924570690 for deletion
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8296171053702472734_1083 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8296171053702472734 for deletion
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8851906794908078937_1090 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8851906794908078937
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3976966448601259965_1096 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3976966448601259965 for deletion
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8685839914547727287_1084 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8685839914547727287
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_897857511034492603_1095 file /tmp/hadoop-sunyan/dfs/data/current/blk_897857511034492603 for deletion
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8427579820924570690_1095 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8427579820924570690
2016-04-25 09:34:20,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1954666784571810447_1085 file /tmp/hadoop-sunyan/dfs/data/current/blk_1954666784571810447 for deletion
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8296171053702472734_1083 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8296171053702472734
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2424889144869988943_1088 file /tmp/hadoop-sunyan/dfs/data/current/blk_2424889144869988943 for deletion
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3976966448601259965_1096 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3976966448601259965
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4231783964767467929_1082 file /tmp/hadoop-sunyan/dfs/data/current/blk_4231783964767467929 for deletion
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_897857511034492603_1095 at file /tmp/hadoop-sunyan/dfs/data/current/blk_897857511034492603
2016-04-25 09:34:20,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4632684579053209134_1089 file /tmp/hadoop-sunyan/dfs/data/current/blk_4632684579053209134 for deletion
2016-04-25 09:34:20,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1954666784571810447_1085 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1954666784571810447
2016-04-25 09:34:20,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8181551804054923749_1086 file /tmp/hadoop-sunyan/dfs/data/current/blk_8181551804054923749 for deletion
2016-04-25 09:34:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2424889144869988943_1088 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2424889144869988943
2016-04-25 09:34:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8685501273118886465_1091 file /tmp/hadoop-sunyan/dfs/data/current/blk_8685501273118886465 for deletion
2016-04-25 09:34:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_9139367798057818897_1093 file /tmp/hadoop-sunyan/dfs/data/current/blk_9139367798057818897 for deletion
2016-04-25 09:34:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4231783964767467929_1082 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4231783964767467929
2016-04-25 09:34:20,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4632684579053209134_1089 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4632684579053209134
2016-04-25 09:34:20,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8181551804054923749_1086 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8181551804054923749
2016-04-25 09:34:20,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8685501273118886465_1091 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8685501273118886465
2016-04-25 09:34:20,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_9139367798057818897_1093 at file /tmp/hadoop-sunyan/dfs/data/current/blk_9139367798057818897
2016-04-25 09:34:22,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7051611989798303774_1097 src: /127.0.0.1:59471 dest: /127.0.0.1:50010
2016-04-25 09:34:22,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59471, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763466004_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7051611989798303774_1097, duration: 5801099
2016-04-25 09:34:22,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7051611989798303774_1097 terminating
2016-04-25 09:34:23,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2270751041405626827_1098 src: /127.0.0.1:59472 dest: /127.0.0.1:50010
2016-04-25 09:34:23,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59472, dest: /127.0.0.1:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763466004_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2270751041405626827_1098, duration: 559482
2016-04-25 09:34:23,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2270751041405626827_1098 terminating
2016-04-25 09:34:23,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8822606276796993411_1099 src: /127.0.0.1:59473 dest: /127.0.0.1:50010
2016-04-25 09:34:23,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59473, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763466004_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8822606276796993411_1099, duration: 835414
2016-04-25 09:34:23,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8822606276796993411_1099 terminating
2016-04-25 09:34:23,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3109038105603857693_1100 src: /127.0.0.1:59474 dest: /127.0.0.1:50010
2016-04-25 09:34:23,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59474, dest: /127.0.0.1:50010, bytes: 34006, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763466004_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3109038105603857693_1100, duration: 1937058
2016-04-25 09:34:23,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3109038105603857693_1100 terminating
2016-04-25 09:34:23,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6175503217185122760_1101 src: /127.0.0.1:59475 dest: /127.0.0.1:50010
2016-04-25 09:34:23,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59475, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6175503217185122760_1101, duration: 1445523
2016-04-25 09:34:23,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6175503217185122760_1101 terminating
2016-04-25 09:34:23,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3597335609577305834_1102 src: /127.0.0.1:59476 dest: /127.0.0.1:50010
2016-04-25 09:34:23,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59476, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3597335609577305834_1102, duration: 1167312
2016-04-25 09:34:23,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3597335609577305834_1102 terminating
2016-04-25 09:34:23,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59478, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_374260946_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3109038105603857693_1100, duration: 348213
2016-04-25 09:34:23,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6598393555257777507_1104 src: /127.0.0.1:59479 dest: /127.0.0.1:50010
2016-04-25 09:34:23,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59479, dest: /127.0.0.1:50010, bytes: 48187, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_374260946_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6598393555257777507_1104, duration: 830344
2016-04-25 09:34:23,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6598393555257777507_1104 terminating
2016-04-25 09:34:23,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59480, bytes: 14, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_374260946_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8822606276796993411_1099, duration: 571310
2016-04-25 09:34:24,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59482, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3597335609577305834_1102, duration: 542581
2016-04-25 09:34:24,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59484, bytes: 34274, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1592211760_341, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3109038105603857693_1100, duration: 537579
2016-04-25 09:34:24,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59485, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1592211760_341, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7051611989798303774_1097, duration: 502207
2016-04-25 09:34:27,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4905073231432686374_1105 src: /127.0.0.1:59490 dest: /127.0.0.1:50010
2016-04-25 09:34:27,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59490, dest: /127.0.0.1:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0014_r_000000_0_-1782333788_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4905073231432686374_1105, duration: 1522067
2016-04-25 09:34:27,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4905073231432686374_1105 terminating
2016-04-25 09:34:30,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8590633588084630439_1106 src: /127.0.0.1:59493 dest: /127.0.0.1:50010
2016-04-25 09:34:30,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59493, dest: /127.0.0.1:50010, bytes: 9170, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_374260946_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8590633588084630439_1106, duration: 876228
2016-04-25 09:34:30,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8590633588084630439_1106 terminating
2016-04-25 09:34:30,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7780702896248825369_1107 src: /127.0.0.1:59494 dest: /127.0.0.1:50010
2016-04-25 09:34:30,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59494, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1763466004_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7780702896248825369_1107, duration: 3202088
2016-04-25 09:34:30,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7780702896248825369_1107 terminating
2016-04-25 09:34:32,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4905073231432686374_1105 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4905073231432686374 for deletion
2016-04-25 09:34:32,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3109038105603857693_1100 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3109038105603857693 for deletion
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4905073231432686374_1105 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4905073231432686374
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2270751041405626827_1098 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2270751041405626827 for deletion
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3109038105603857693_1100 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3109038105603857693
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3597335609577305834_1102 file /tmp/hadoop-sunyan/dfs/data/current/blk_3597335609577305834 for deletion
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2270751041405626827_1098 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2270751041405626827
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6175503217185122760_1101 file /tmp/hadoop-sunyan/dfs/data/current/blk_6175503217185122760 for deletion
2016-04-25 09:34:32,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3597335609577305834_1102 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3597335609577305834
2016-04-25 09:34:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6598393555257777507_1104 file /tmp/hadoop-sunyan/dfs/data/current/blk_6598393555257777507 for deletion
2016-04-25 09:34:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6175503217185122760_1101 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6175503217185122760
2016-04-25 09:34:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7051611989798303774_1097 file /tmp/hadoop-sunyan/dfs/data/current/blk_7051611989798303774 for deletion
2016-04-25 09:34:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6598393555257777507_1104 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6598393555257777507
2016-04-25 09:34:32,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8590633588084630439_1106 file /tmp/hadoop-sunyan/dfs/data/current/blk_8590633588084630439 for deletion
2016-04-25 09:34:32,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7051611989798303774_1097 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7051611989798303774
2016-04-25 09:34:32,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8822606276796993411_1099 file /tmp/hadoop-sunyan/dfs/data/current/blk_8822606276796993411 for deletion
2016-04-25 09:34:32,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8590633588084630439_1106 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8590633588084630439
2016-04-25 09:34:32,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8822606276796993411_1099 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8822606276796993411
2016-04-25 09:36:05,811 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_-5347238566961441633_1011
2016-04-25 09:40:35,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7180837930137877946_1108 src: /127.0.0.1:59497 dest: /127.0.0.1:50010
2016-04-25 09:40:35,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59497, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7180837930137877946_1108, duration: 2525837
2016-04-25 09:40:35,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7180837930137877946_1108 terminating
2016-04-25 09:40:35,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4460930001272206841_1109 src: /127.0.0.1:59498 dest: /127.0.0.1:50010
2016-04-25 09:40:35,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59498, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4460930001272206841_1109, duration: 658696
2016-04-25 09:40:35,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4460930001272206841_1109 terminating
2016-04-25 09:40:35,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4623928970212051222_1110 src: /127.0.0.1:59499 dest: /127.0.0.1:50010
2016-04-25 09:40:35,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59499, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4623928970212051222_1110, duration: 611008
2016-04-25 09:40:35,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4623928970212051222_1110 terminating
2016-04-25 09:40:35,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4798659789342225251_1111 src: /127.0.0.1:59500 dest: /127.0.0.1:50010
2016-04-25 09:40:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59500, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4798659789342225251_1111, duration: 614670
2016-04-25 09:40:35,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4798659789342225251_1111 terminating
2016-04-25 09:40:36,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_464846577246742551_1112 src: /127.0.0.1:59502 dest: /127.0.0.1:50010
2016-04-25 09:40:36,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59502, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_464846577246742551_1112, duration: 1692537
2016-04-25 09:40:36,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_464846577246742551_1112 terminating
2016-04-25 09:40:36,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1218044237546964972_1113 src: /127.0.0.1:59503 dest: /127.0.0.1:50010
2016-04-25 09:40:36,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59503, dest: /127.0.0.1:50010, bytes: 499, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1218044237546964972_1113, duration: 624499
2016-04-25 09:40:36,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1218044237546964972_1113 terminating
2016-04-25 09:40:36,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-9174032431415172684_1114 src: /127.0.0.1:59504 dest: /127.0.0.1:50010
2016-04-25 09:40:36,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59504, dest: /127.0.0.1:50010, bytes: 54, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-9174032431415172684_1114, duration: 749474
2016-04-25 09:40:36,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-9174032431415172684_1114 terminating
2016-04-25 09:40:36,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6149108980363266485_1115 src: /127.0.0.1:59505 dest: /127.0.0.1:50010
2016-04-25 09:40:36,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59505, dest: /127.0.0.1:50010, bytes: 33938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6149108980363266485_1115, duration: 726325
2016-04-25 09:40:36,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6149108980363266485_1115 terminating
2016-04-25 09:40:36,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8900367006772583753_1116 src: /127.0.0.1:59507 dest: /127.0.0.1:50010
2016-04-25 09:40:36,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59507, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8900367006772583753_1116, duration: 602125
2016-04-25 09:40:36,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8900367006772583753_1116 terminating
2016-04-25 09:40:36,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6385183158536210897_1117 src: /127.0.0.1:59508 dest: /127.0.0.1:50010
2016-04-25 09:40:36,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59508, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6385183158536210897_1117, duration: 1092772
2016-04-25 09:40:36,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6385183158536210897_1117 terminating
2016-04-25 09:40:36,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59510, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_882119613_26, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6149108980363266485_1115, duration: 727890
2016-04-25 09:40:36,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7038145282017746405_1119 src: /127.0.0.1:59511 dest: /127.0.0.1:50010
2016-04-25 09:40:36,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59511, dest: /127.0.0.1:50010, bytes: 48091, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_882119613_26, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7038145282017746405_1119, duration: 1230986
2016-04-25 09:40:36,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7038145282017746405_1119 terminating
2016-04-25 09:40:36,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59512, bytes: 58, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_882119613_26, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-9174032431415172684_1114, duration: 581403
2016-04-25 09:40:37,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59514, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6385183158536210897_1117, duration: 340639
2016-04-25 09:40:37,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59516, bytes: 34206, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-436044906_368, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6149108980363266485_1115, duration: 459636
2016-04-25 09:40:37,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59517, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-436044906_368, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_464846577246742551_1112, duration: 489487
2016-04-25 09:40:40,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59524, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000000_0_-755662159_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1218044237546964972_1113, duration: 216745
2016-04-25 09:40:40,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59525, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000000_0_-755662159_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7180837930137877946_1108, duration: 235771
2016-04-25 09:40:40,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59526, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000001_0_254798137_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1218044237546964972_1113, duration: 237224
2016-04-25 09:40:40,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59527, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000001_0_254798137_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4460930001272206841_1109, duration: 237135
2016-04-25 09:40:43,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59533, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000002_0_-756427163_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1218044237546964972_1113, duration: 208743
2016-04-25 09:40:43,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59535, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000002_0_-756427163_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4623928970212051222_1110, duration: 240213
2016-04-25 09:40:43,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59536, bytes: 503, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000003_0_936019515_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1218044237546964972_1113, duration: 220263
2016-04-25 09:40:43,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59537, bytes: 122, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0016_m_000003_0_936019515_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4798659789342225251_1111, duration: 211333
2016-04-25 09:40:49,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7015807710997046970_1121 src: /127.0.0.1:59539 dest: /127.0.0.1:50010
2016-04-25 09:40:49,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59539, dest: /127.0.0.1:50010, bytes: 118, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0016_r_000000_0_-1025120213_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7015807710997046970_1121, duration: 2223740
2016-04-25 09:40:49,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7015807710997046970_1121 terminating
2016-04-25 09:40:49,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5367978552674197168_1121 src: /127.0.0.1:59540 dest: /127.0.0.1:50010
2016-04-25 09:40:49,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59540, dest: /127.0.0.1:50010, bytes: 97, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0016_r_000000_0_-1025120213_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5367978552674197168_1121, duration: 779074
2016-04-25 09:40:49,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5367978552674197168_1121 terminating
2016-04-25 09:40:52,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8075637692662567141_1122 src: /127.0.0.1:59544 dest: /127.0.0.1:50010
2016-04-25 09:40:52,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59544, dest: /127.0.0.1:50010, bytes: 22062, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_882119613_26, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8075637692662567141_1122, duration: 1351931
2016-04-25 09:40:52,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8075637692662567141_1122 terminating
2016-04-25 09:40:52,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59547, bytes: 122, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1449726974_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7015807710997046970_1121, duration: 198041
2016-04-25 09:40:53,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-9174032431415172684_1114 file /tmp/hadoop-sunyan/dfs/data/current/blk_-9174032431415172684 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6385183158536210897_1117 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6385183158536210897 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-9174032431415172684_1114 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-9174032431415172684
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6149108980363266485_1115 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6149108980363266485 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6385183158536210897_1117 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6385183158536210897
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_464846577246742551_1112 file /tmp/hadoop-sunyan/dfs/data/current/blk_464846577246742551 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6149108980363266485_1115 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6149108980363266485
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1218044237546964972_1113 file /tmp/hadoop-sunyan/dfs/data/current/blk_1218044237546964972 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8900367006772583753_1116 file /tmp/hadoop-sunyan/dfs/data/current/blk_8900367006772583753 for deletion
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_464846577246742551_1112 at file /tmp/hadoop-sunyan/dfs/data/current/blk_464846577246742551
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1218044237546964972_1113 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1218044237546964972
2016-04-25 09:40:53,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8900367006772583753_1116 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8900367006772583753
2016-04-25 09:40:56,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8075637692662567141_1122 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8075637692662567141 for deletion
2016-04-25 09:40:56,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-7180837930137877946_1108 file /tmp/hadoop-sunyan/dfs/data/current/blk_-7180837930137877946 for deletion
2016-04-25 09:40:56,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8075637692662567141_1122 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8075637692662567141
2016-04-25 09:40:56,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5367978552674197168_1121 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5367978552674197168 for deletion
2016-04-25 09:40:56,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-7180837930137877946_1108 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-7180837930137877946
2016-04-25 09:40:56,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4460930001272206841_1109 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4460930001272206841 for deletion
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5367978552674197168_1121 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5367978552674197168
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4623928970212051222_1110 file /tmp/hadoop-sunyan/dfs/data/current/blk_4623928970212051222 for deletion
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4460930001272206841_1109 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4460930001272206841
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4798659789342225251_1111 file /tmp/hadoop-sunyan/dfs/data/current/blk_4798659789342225251 for deletion
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4623928970212051222_1110 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4623928970212051222
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7015807710997046970_1121 file /tmp/hadoop-sunyan/dfs/data/current/blk_7015807710997046970 for deletion
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4798659789342225251_1111 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4798659789342225251
2016-04-25 09:40:56,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7038145282017746405_1119 file /tmp/hadoop-sunyan/dfs/data/current/blk_7038145282017746405 for deletion
2016-04-25 09:40:56,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7015807710997046970_1121 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7015807710997046970
2016-04-25 09:40:56,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7038145282017746405_1119 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7038145282017746405
2016-04-25 09:47:23,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6910622349362768719_1123 src: /127.0.0.1:59553 dest: /127.0.0.1:50010
2016-04-25 09:47:23,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59553, dest: /127.0.0.1:50010, bytes: 4644, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6910622349362768719_1123, duration: 8364671
2016-04-25 09:47:23,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6910622349362768719_1123 terminating
2016-04-25 09:47:23,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1762988281400182139_1124 src: /127.0.0.1:59554 dest: /127.0.0.1:50010
2016-04-25 09:47:23,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59554, dest: /127.0.0.1:50010, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1762988281400182139_1124, duration: 767328
2016-04-25 09:47:23,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1762988281400182139_1124 terminating
2016-04-25 09:47:23,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_9085283366252724518_1125 src: /127.0.0.1:59555 dest: /127.0.0.1:50010
2016-04-25 09:47:23,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59555, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9085283366252724518_1125, duration: 468851
2016-04-25 09:47:23,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_9085283366252724518_1125 terminating
2016-04-25 09:47:23,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2449646715925200867_1126 src: /127.0.0.1:59556 dest: /127.0.0.1:50010
2016-04-25 09:47:23,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59556, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2449646715925200867_1126, duration: 514727
2016-04-25 09:47:23,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2449646715925200867_1126 terminating
2016-04-25 09:47:23,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6001246101691983523_1127 src: /127.0.0.1:59557 dest: /127.0.0.1:50010
2016-04-25 09:47:23,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59557, dest: /127.0.0.1:50010, bytes: 3890, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6001246101691983523_1127, duration: 688837
2016-04-25 09:47:23,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6001246101691983523_1127 terminating
2016-04-25 09:47:23,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4743769251459017536_1128 src: /127.0.0.1:59558 dest: /127.0.0.1:50010
2016-04-25 09:47:23,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59558, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4743769251459017536_1128, duration: 919082
2016-04-25 09:47:23,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4743769251459017536_1128 terminating
2016-04-25 09:47:23,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6890304355705357255_1129 src: /127.0.0.1:59559 dest: /127.0.0.1:50010
2016-04-25 09:47:23,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59559, dest: /127.0.0.1:50010, bytes: 382, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6890304355705357255_1129, duration: 586801
2016-04-25 09:47:23,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6890304355705357255_1129 terminating
2016-04-25 09:47:23,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8579421917861991865_1130 src: /127.0.0.1:59560 dest: /127.0.0.1:50010
2016-04-25 09:47:23,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59560, dest: /127.0.0.1:50010, bytes: 2033, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8579421917861991865_1130, duration: 776934
2016-04-25 09:47:23,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8579421917861991865_1130 terminating
2016-04-25 09:47:23,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5087938880086150591_1131 src: /127.0.0.1:59561 dest: /127.0.0.1:50010
2016-04-25 09:47:23,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59561, dest: /127.0.0.1:50010, bytes: 2435, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5087938880086150591_1131, duration: 559421
2016-04-25 09:47:23,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5087938880086150591_1131 terminating
2016-04-25 09:47:23,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2433956172088958821_1132 src: /127.0.0.1:59562 dest: /127.0.0.1:50010
2016-04-25 09:47:23,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59562, dest: /127.0.0.1:50010, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2433956172088958821_1132, duration: 522844
2016-04-25 09:47:23,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2433956172088958821_1132 terminating
2016-04-25 09:47:23,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3774737858027559243_1133 src: /127.0.0.1:59563 dest: /127.0.0.1:50010
2016-04-25 09:47:23,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59563, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3774737858027559243_1133, duration: 974800
2016-04-25 09:47:23,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3774737858027559243_1133 terminating
2016-04-25 09:47:23,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-861099209899576624_1134 src: /127.0.0.1:59564 dest: /127.0.0.1:50010
2016-04-25 09:47:23,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59564, dest: /127.0.0.1:50010, bytes: 327, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-861099209899576624_1134, duration: 739794
2016-04-25 09:47:23,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-861099209899576624_1134 terminating
2016-04-25 09:47:23,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7578617192995555560_1135 src: /127.0.0.1:59565 dest: /127.0.0.1:50010
2016-04-25 09:47:23,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59565, dest: /127.0.0.1:50010, bytes: 1095, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7578617192995555560_1135, duration: 820642
2016-04-25 09:47:23,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7578617192995555560_1135 terminating
2016-04-25 09:47:23,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5291400298796111750_1136 src: /127.0.0.1:59566 dest: /127.0.0.1:50010
2016-04-25 09:47:23,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59566, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5291400298796111750_1136, duration: 560333
2016-04-25 09:47:23,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5291400298796111750_1136 terminating
2016-04-25 09:47:23,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7805977499826869644_1137 src: /127.0.0.1:59567 dest: /127.0.0.1:50010
2016-04-25 09:47:23,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59567, dest: /127.0.0.1:50010, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7805977499826869644_1137, duration: 477488
2016-04-25 09:47:23,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7805977499826869644_1137 terminating
2016-04-25 09:47:23,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2887749043355516015_1138 src: /127.0.0.1:59568 dest: /127.0.0.1:50010
2016-04-25 09:47:23,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59568, dest: /127.0.0.1:50010, bytes: 5018, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2887749043355516015_1138, duration: 754751
2016-04-25 09:47:23,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2887749043355516015_1138 terminating
2016-04-25 09:47:23,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6262231885904692593_1139 src: /127.0.0.1:59569 dest: /127.0.0.1:50010
2016-04-25 09:47:23,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59569, dest: /127.0.0.1:50010, bytes: 7457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1157629437_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6262231885904692593_1139, duration: 1228027
2016-04-25 09:47:23,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6262231885904692593_1139 terminating
2016-04-25 09:47:59,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_559580020134982364_1140 src: /127.0.0.1:59572 dest: /127.0.0.1:50010
2016-04-25 09:47:59,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59572, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1005090691_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_559580020134982364_1140, duration: 3176606
2016-04-25 09:47:59,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_559580020134982364_1140 terminating
2016-04-25 09:47:59,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6585937199727013647_1141 src: /127.0.0.1:59573 dest: /127.0.0.1:50010
2016-04-25 09:47:59,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59573, dest: /127.0.0.1:50010, bytes: 117, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1005090691_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6585937199727013647_1141, duration: 711587
2016-04-25 09:47:59,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6585937199727013647_1141 terminating
2016-04-25 09:47:59,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5450844299030944650_1142 src: /127.0.0.1:59574 dest: /127.0.0.1:50010
2016-04-25 09:47:59,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59574, dest: /127.0.0.1:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1005090691_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5450844299030944650_1142, duration: 4155588
2016-04-25 09:47:59,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5450844299030944650_1142 terminating
2016-04-25 09:47:59,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3328625967697602095_1143 src: /127.0.0.1:59575 dest: /127.0.0.1:50010
2016-04-25 09:47:59,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59575, dest: /127.0.0.1:50010, bytes: 33930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1005090691_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3328625967697602095_1143, duration: 1695311
2016-04-25 09:47:59,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3328625967697602095_1143 terminating
2016-04-25 09:47:59,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1775979019181616989_1144 src: /127.0.0.1:59577 dest: /127.0.0.1:50010
2016-04-25 09:47:59,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59577, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1775979019181616989_1144, duration: 524738
2016-04-25 09:47:59,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1775979019181616989_1144 terminating
2016-04-25 09:47:59,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6543159585023041681_1145 src: /127.0.0.1:59578 dest: /127.0.0.1:50010
2016-04-25 09:47:59,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59578, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6543159585023041681_1145, duration: 777119
2016-04-25 09:47:59,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6543159585023041681_1145 terminating
2016-04-25 09:47:59,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59580, bytes: 34198, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1819310225_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3328625967697602095_1143, duration: 352198
2016-04-25 09:47:59,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2290231528887759013_1147 src: /127.0.0.1:59581 dest: /127.0.0.1:50010
2016-04-25 09:47:59,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59581, dest: /127.0.0.1:50010, bytes: 48111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1819310225_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2290231528887759013_1147, duration: 1025140
2016-04-25 09:47:59,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2290231528887759013_1147 terminating
2016-04-25 09:47:59,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59582, bytes: 17, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1819310225_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5450844299030944650_1142, duration: 259137
2016-04-25 09:47:59,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59584, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6543159585023041681_1145, duration: 405038
2016-04-25 09:47:59,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59586, bytes: 34198, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2088684770_434, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3328625967697602095_1143, duration: 408740
2016-04-25 09:47:59,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59587, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2088684770_434, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_559580020134982364_1140, duration: 459024
2016-04-25 09:48:02,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59592, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0017_m_000000_0_-850521188_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6585937199727013647_1141, duration: 143129
2016-04-25 09:48:06,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59596, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0017_m_000000_1_-2084437083_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6585937199727013647_1141, duration: 2456133
2016-04-25 09:48:11,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59599, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0017_m_000000_2_894580333_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6585937199727013647_1141, duration: 241063
2016-04-25 09:48:16,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59603, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0017_m_000000_3_1712426260_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6585937199727013647_1141, duration: 193871
2016-04-25 09:48:20,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_199443913963001735_1147 src: /127.0.0.1:59607 dest: /127.0.0.1:50010
2016-04-25 09:48:20,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59607, dest: /127.0.0.1:50010, bytes: 12655, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1819310225_34, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_199443913963001735_1147, duration: 1171512
2016-04-25 09:48:20,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_199443913963001735_1147 terminating
2016-04-25 09:48:23,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_559580020134982364_1140 file /tmp/hadoop-sunyan/dfs/data/current/blk_559580020134982364 for deletion
2016-04-25 09:48:23,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1775979019181616989_1144 file /tmp/hadoop-sunyan/dfs/data/current/blk_1775979019181616989 for deletion
2016-04-25 09:48:23,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_559580020134982364_1140 at file /tmp/hadoop-sunyan/dfs/data/current/blk_559580020134982364
2016-04-25 09:48:23,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3328625967697602095_1143 file /tmp/hadoop-sunyan/dfs/data/current/blk_3328625967697602095 for deletion
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1775979019181616989_1144 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1775979019181616989
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5450844299030944650_1142 file /tmp/hadoop-sunyan/dfs/data/current/blk_5450844299030944650 for deletion
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3328625967697602095_1143 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3328625967697602095
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6543159585023041681_1145 file /tmp/hadoop-sunyan/dfs/data/current/blk_6543159585023041681 for deletion
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5450844299030944650_1142 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5450844299030944650
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6585937199727013647_1141 file /tmp/hadoop-sunyan/dfs/data/current/blk_6585937199727013647 for deletion
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6543159585023041681_1145 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6543159585023041681
2016-04-25 09:48:23,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6585937199727013647_1141 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6585937199727013647
2016-04-25 09:49:07,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6036907074199693906_1148 src: /127.0.0.1:59614 dest: /127.0.0.1:50010
2016-04-25 09:49:07,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59614, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1932190360_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6036907074199693906_1148, duration: 2479294
2016-04-25 09:49:07,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6036907074199693906_1148 terminating
2016-04-25 09:49:10,930 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_-7862356526682066269_1048
2016-04-25 09:49:31,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7064614453798335373_1149 src: /127.0.0.1:59617 dest: /127.0.0.1:50010
2016-04-25 09:49:31,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59617, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1820463027_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7064614453798335373_1149, duration: 4079342
2016-04-25 09:49:31,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7064614453798335373_1149 terminating
2016-04-25 09:49:32,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1985086578927933899_1150 src: /127.0.0.1:59618 dest: /127.0.0.1:50010
2016-04-25 09:49:32,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59618, dest: /127.0.0.1:50010, bytes: 117, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1820463027_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1985086578927933899_1150, duration: 665890
2016-04-25 09:49:32,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1985086578927933899_1150 terminating
2016-04-25 09:49:32,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6676402702640359194_1151 src: /127.0.0.1:59619 dest: /127.0.0.1:50010
2016-04-25 09:49:32,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59619, dest: /127.0.0.1:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1820463027_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6676402702640359194_1151, duration: 643115
2016-04-25 09:49:32,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6676402702640359194_1151 terminating
2016-04-25 09:49:32,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5736932946361766614_1152 src: /127.0.0.1:59620 dest: /127.0.0.1:50010
2016-04-25 09:49:32,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59620, dest: /127.0.0.1:50010, bytes: 33930, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1820463027_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5736932946361766614_1152, duration: 3069853
2016-04-25 09:49:32,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5736932946361766614_1152 terminating
2016-04-25 09:49:32,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8026142950367727209_1153 src: /127.0.0.1:59622 dest: /127.0.0.1:50010
2016-04-25 09:49:32,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59622, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8026142950367727209_1153, duration: 714886
2016-04-25 09:49:32,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8026142950367727209_1153 terminating
2016-04-25 09:49:32,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2571919066266860613_1154 src: /127.0.0.1:59623 dest: /127.0.0.1:50010
2016-04-25 09:49:32,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59623, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2571919066266860613_1154, duration: 964844
2016-04-25 09:49:32,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2571919066266860613_1154 terminating
2016-04-25 09:49:32,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59625, bytes: 34198, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2032947372_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5736932946361766614_1152, duration: 333606
2016-04-25 09:49:32,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1858211735133720239_1156 src: /127.0.0.1:59626 dest: /127.0.0.1:50010
2016-04-25 09:49:32,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59626, dest: /127.0.0.1:50010, bytes: 48111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2032947372_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1858211735133720239_1156, duration: 1069920
2016-04-25 09:49:32,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1858211735133720239_1156 terminating
2016-04-25 09:49:32,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59627, bytes: 17, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_2032947372_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6676402702640359194_1151, duration: 339848
2016-04-25 09:49:32,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59629, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2571919066266860613_1154, duration: 182978
2016-04-25 09:49:32,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59631, bytes: 34198, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_943042303_500, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5736932946361766614_1152, duration: 295132
2016-04-25 09:49:32,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59632, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_943042303_500, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7064614453798335373_1149, duration: 524676
2016-04-25 09:49:35,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59637, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0019_m_000000_0_-1989903724_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1985086578927933899_1150, duration: 151485
2016-04-25 09:49:39,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59641, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0019_m_000000_1_-1498239945_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1985086578927933899_1150, duration: 189646
2016-04-25 09:49:44,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59644, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0019_m_000000_2_599056942_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1985086578927933899_1150, duration: 182434
2016-04-25 09:49:48,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59648, bytes: 121, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0019_m_000000_3_2072044491_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1985086578927933899_1150, duration: 172980
2016-04-25 09:49:53,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-180553659336417085_1156 src: /127.0.0.1:59652 dest: /127.0.0.1:50010
2016-04-25 09:49:53,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59652, dest: /127.0.0.1:50010, bytes: 12655, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2032947372_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-180553659336417085_1156, duration: 612752
2016-04-25 09:49:53,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-180553659336417085_1156 terminating
2016-04-25 09:49:56,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8026142950367727209_1153 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8026142950367727209 for deletion
2016-04-25 09:49:56,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1985086578927933899_1150 file /tmp/hadoop-sunyan/dfs/data/current/blk_1985086578927933899 for deletion
2016-04-25 09:49:56,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2571919066266860613_1154 file /tmp/hadoop-sunyan/dfs/data/current/blk_2571919066266860613 for deletion
2016-04-25 09:49:56,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8026142950367727209_1153 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8026142950367727209
2016-04-25 09:49:56,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5736932946361766614_1152 file /tmp/hadoop-sunyan/dfs/data/current/blk_5736932946361766614 for deletion
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1985086578927933899_1150 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1985086578927933899
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6676402702640359194_1151 file /tmp/hadoop-sunyan/dfs/data/current/blk_6676402702640359194 for deletion
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7064614453798335373_1149 file /tmp/hadoop-sunyan/dfs/data/current/blk_7064614453798335373 for deletion
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2571919066266860613_1154 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2571919066266860613
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5736932946361766614_1152 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5736932946361766614
2016-04-25 09:49:56,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6676402702640359194_1151 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6676402702640359194
2016-04-25 09:49:56,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7064614453798335373_1149 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7064614453798335373
2016-04-25 09:55:23,992 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_-8579421917861991865_1130
2016-04-25 10:01:21,052 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_7780702896248825369_1107
2016-04-25 10:02:11,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8579421917861991865_1130 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8579421917861991865 for deletion
2016-04-25 10:02:11,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-7805977499826869644_1137 file /tmp/hadoop-sunyan/dfs/data/current/blk_-7805977499826869644 for deletion
2016-04-25 10:02:11,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6262231885904692593_1139 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6262231885904692593 for deletion
2016-04-25 10:02:11,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8579421917861991865_1130 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8579421917861991865
2016-04-25 10:02:11,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6001246101691983523_1127 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6001246101691983523 for deletion
2016-04-25 10:02:11,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5347238566961441633_1011 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5347238566961441633 for deletion
2016-04-25 10:02:11,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4743769251459017536_1128 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4743769251459017536 for deletion
2016-04-25 10:02:11,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3774737858027559243_1133 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3774737858027559243 for deletion
2016-04-25 10:02:11,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2887749043355516015_1138 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2887749043355516015 for deletion
2016-04-25 10:02:11,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2449646715925200867_1126 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2449646715925200867 for deletion
2016-04-25 10:02:11,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2433956172088958821_1132 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2433956172088958821 for deletion
2016-04-25 10:02:11,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2290231528887759013_1147 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2290231528887759013 for deletion
2016-04-25 10:02:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-861099209899576624_1134 file /tmp/hadoop-sunyan/dfs/data/current/blk_-861099209899576624 for deletion
2016-04-25 10:02:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-180553659336417085_1156 file /tmp/hadoop-sunyan/dfs/data/current/blk_-180553659336417085 for deletion
2016-04-25 10:02:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_199443913963001735_1147 file /tmp/hadoop-sunyan/dfs/data/current/blk_199443913963001735 for deletion
2016-04-25 10:02:11,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1762988281400182139_1124 file /tmp/hadoop-sunyan/dfs/data/current/blk_1762988281400182139 for deletion
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1858211735133720239_1156 file /tmp/hadoop-sunyan/dfs/data/current/blk_1858211735133720239 for deletion
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5033466763869055520_1009 file /tmp/hadoop-sunyan/dfs/data/current/blk_5033466763869055520 for deletion
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5087938880086150591_1131 file /tmp/hadoop-sunyan/dfs/data/current/blk_5087938880086150591 for deletion
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-7805977499826869644_1137 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-7805977499826869644
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5291400298796111750_1136 file /tmp/hadoop-sunyan/dfs/data/current/blk_5291400298796111750 for deletion
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6262231885904692593_1139 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6262231885904692593
2016-04-25 10:02:11,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6890304355705357255_1129 file /tmp/hadoop-sunyan/dfs/data/current/blk_6890304355705357255 for deletion
2016-04-25 10:02:11,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6910622349362768719_1123 file /tmp/hadoop-sunyan/dfs/data/current/blk_6910622349362768719 for deletion
2016-04-25 10:02:11,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7578617192995555560_1135 file /tmp/hadoop-sunyan/dfs/data/current/blk_7578617192995555560 for deletion
2016-04-25 10:02:11,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_9085283366252724518_1125 file /tmp/hadoop-sunyan/dfs/data/current/blk_9085283366252724518 for deletion
2016-04-25 10:02:11,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6001246101691983523_1127 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6001246101691983523
2016-04-25 10:02:11,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5347238566961441633_1011 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5347238566961441633
2016-04-25 10:02:11,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4743769251459017536_1128 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4743769251459017536
2016-04-25 10:02:11,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3774737858027559243_1133 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3774737858027559243
2016-04-25 10:02:11,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2887749043355516015_1138 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2887749043355516015
2016-04-25 10:02:11,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2449646715925200867_1126 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2449646715925200867
2016-04-25 10:02:11,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2433956172088958821_1132 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2433956172088958821
2016-04-25 10:02:11,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2290231528887759013_1147 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2290231528887759013
2016-04-25 10:02:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-861099209899576624_1134 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-861099209899576624
2016-04-25 10:02:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-180553659336417085_1156 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-180553659336417085
2016-04-25 10:02:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_199443913963001735_1147 at file /tmp/hadoop-sunyan/dfs/data/current/blk_199443913963001735
2016-04-25 10:02:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1762988281400182139_1124 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1762988281400182139
2016-04-25 10:02:11,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1858211735133720239_1156 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1858211735133720239
2016-04-25 10:02:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5033466763869055520_1009 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5033466763869055520
2016-04-25 10:02:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5087938880086150591_1131 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5087938880086150591
2016-04-25 10:02:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5291400298796111750_1136 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5291400298796111750
2016-04-25 10:02:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6890304355705357255_1129 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6890304355705357255
2016-04-25 10:02:11,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6910622349362768719_1123 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6910622349362768719
2016-04-25 10:02:11,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7578617192995555560_1135 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7578617192995555560
2016-04-25 10:02:11,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_9085283366252724518_1125 at file /tmp/hadoop-sunyan/dfs/data/current/blk_9085283366252724518
2016-04-25 10:03:43,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7248583666356218423_1157 src: /127.0.0.1:59686 dest: /127.0.0.1:50010
2016-04-25 10:03:43,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59686, dest: /127.0.0.1:50010, bytes: 4644, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7248583666356218423_1157, duration: 2374876
2016-04-25 10:03:43,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7248583666356218423_1157 terminating
2016-04-25 10:03:43,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1601590551805194070_1158 src: /127.0.0.1:59687 dest: /127.0.0.1:50010
2016-04-25 10:03:43,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59687, dest: /127.0.0.1:50010, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1601590551805194070_1158, duration: 941564
2016-04-25 10:03:43,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1601590551805194070_1158 terminating
2016-04-25 10:03:43,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7437308821345963474_1159 src: /127.0.0.1:59688 dest: /127.0.0.1:50010
2016-04-25 10:03:43,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59688, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7437308821345963474_1159, duration: 1028958
2016-04-25 10:03:43,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7437308821345963474_1159 terminating
2016-04-25 10:03:43,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2553820079981493955_1160 src: /127.0.0.1:59689 dest: /127.0.0.1:50010
2016-04-25 10:03:43,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59689, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2553820079981493955_1160, duration: 305759
2016-04-25 10:03:43,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2553820079981493955_1160 terminating
2016-04-25 10:03:43,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3595889647529002689_1161 src: /127.0.0.1:59690 dest: /127.0.0.1:50010
2016-04-25 10:03:43,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59690, dest: /127.0.0.1:50010, bytes: 3890, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3595889647529002689_1161, duration: 573020
2016-04-25 10:03:43,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3595889647529002689_1161 terminating
2016-04-25 10:03:43,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6554540595342828336_1162 src: /127.0.0.1:59691 dest: /127.0.0.1:50010
2016-04-25 10:03:43,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59691, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6554540595342828336_1162, duration: 1057479
2016-04-25 10:03:43,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6554540595342828336_1162 terminating
2016-04-25 10:03:43,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5853284561847869870_1163 src: /127.0.0.1:59692 dest: /127.0.0.1:50010
2016-04-25 10:03:43,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59692, dest: /127.0.0.1:50010, bytes: 382, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5853284561847869870_1163, duration: 566426
2016-04-25 10:03:43,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5853284561847869870_1163 terminating
2016-04-25 10:03:43,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8356562533597903371_1164 src: /127.0.0.1:59693 dest: /127.0.0.1:50010
2016-04-25 10:03:43,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59693, dest: /127.0.0.1:50010, bytes: 2033, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8356562533597903371_1164, duration: 929938
2016-04-25 10:03:43,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8356562533597903371_1164 terminating
2016-04-25 10:03:43,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3305161679708000155_1165 src: /127.0.0.1:59694 dest: /127.0.0.1:50010
2016-04-25 10:03:43,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59694, dest: /127.0.0.1:50010, bytes: 2435, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3305161679708000155_1165, duration: 818082
2016-04-25 10:03:43,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3305161679708000155_1165 terminating
2016-04-25 10:03:43,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4351328915959681067_1166 src: /127.0.0.1:59695 dest: /127.0.0.1:50010
2016-04-25 10:03:43,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59695, dest: /127.0.0.1:50010, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4351328915959681067_1166, duration: 791242
2016-04-25 10:03:43,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4351328915959681067_1166 terminating
2016-04-25 10:03:43,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8426246290081429697_1167 src: /127.0.0.1:59696 dest: /127.0.0.1:50010
2016-04-25 10:03:43,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59696, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8426246290081429697_1167, duration: 566821
2016-04-25 10:03:43,654 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8426246290081429697_1167 terminating
2016-04-25 10:03:43,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3733339673635437004_1168 src: /127.0.0.1:59697 dest: /127.0.0.1:50010
2016-04-25 10:03:43,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59697, dest: /127.0.0.1:50010, bytes: 327, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3733339673635437004_1168, duration: 643102
2016-04-25 10:03:43,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3733339673635437004_1168 terminating
2016-04-25 10:03:43,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4932533327608509314_1169 src: /127.0.0.1:59698 dest: /127.0.0.1:50010
2016-04-25 10:03:43,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59698, dest: /127.0.0.1:50010, bytes: 1095, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4932533327608509314_1169, duration: 767073
2016-04-25 10:03:43,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4932533327608509314_1169 terminating
2016-04-25 10:03:43,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3710839777630803774_1170 src: /127.0.0.1:59699 dest: /127.0.0.1:50010
2016-04-25 10:03:43,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59699, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3710839777630803774_1170, duration: 2456622
2016-04-25 10:03:43,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3710839777630803774_1170 terminating
2016-04-25 10:03:43,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4210050728670664457_1171 src: /127.0.0.1:59700 dest: /127.0.0.1:50010
2016-04-25 10:03:43,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59700, dest: /127.0.0.1:50010, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4210050728670664457_1171, duration: 342795
2016-04-25 10:03:43,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4210050728670664457_1171 terminating
2016-04-25 10:03:44,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8400922851087964744_1172 src: /127.0.0.1:59701 dest: /127.0.0.1:50010
2016-04-25 10:03:44,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59701, dest: /127.0.0.1:50010, bytes: 5018, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8400922851087964744_1172, duration: 1126509
2016-04-25 10:03:44,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8400922851087964744_1172 terminating
2016-04-25 10:03:44,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2587576046744126236_1173 src: /127.0.0.1:59702 dest: /127.0.0.1:50010
2016-04-25 10:03:44,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59702, dest: /127.0.0.1:50010, bytes: 7457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-684227962_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2587576046744126236_1173, duration: 384765
2016-04-25 10:03:44,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2587576046744126236_1173 terminating
2016-04-25 10:04:56,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8400922851087964744_1172 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8400922851087964744 for deletion
2016-04-25 10:04:56,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-7248583666356218423_1157 file /tmp/hadoop-sunyan/dfs/data/current/blk_-7248583666356218423 for deletion
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5853284561847869870_1163 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5853284561847869870 for deletion
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4210050728670664457_1171 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4210050728670664457 for deletion
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8400922851087964744_1172 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8400922851087964744
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3733339673635437004_1168 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3733339673635437004 for deletion
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3595889647529002689_1161 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3595889647529002689 for deletion
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-7248583666356218423_1157 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-7248583666356218423
2016-04-25 10:04:56,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1601590551805194070_1158 file /tmp/hadoop-sunyan/dfs/data/current/blk_1601590551805194070 for deletion
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2553820079981493955_1160 file /tmp/hadoop-sunyan/dfs/data/current/blk_2553820079981493955 for deletion
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5853284561847869870_1163 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5853284561847869870
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2587576046744126236_1173 file /tmp/hadoop-sunyan/dfs/data/current/blk_2587576046744126236 for deletion
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3305161679708000155_1165 file /tmp/hadoop-sunyan/dfs/data/current/blk_3305161679708000155 for deletion
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4210050728670664457_1171 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4210050728670664457
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3710839777630803774_1170 file /tmp/hadoop-sunyan/dfs/data/current/blk_3710839777630803774 for deletion
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3733339673635437004_1168 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3733339673635437004
2016-04-25 10:04:56,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4351328915959681067_1166 file /tmp/hadoop-sunyan/dfs/data/current/blk_4351328915959681067 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4932533327608509314_1169 file /tmp/hadoop-sunyan/dfs/data/current/blk_4932533327608509314 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3595889647529002689_1161 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3595889647529002689
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6554540595342828336_1162 file /tmp/hadoop-sunyan/dfs/data/current/blk_6554540595342828336 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7437308821345963474_1159 file /tmp/hadoop-sunyan/dfs/data/current/blk_7437308821345963474 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1601590551805194070_1158 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1601590551805194070
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8356562533597903371_1164 file /tmp/hadoop-sunyan/dfs/data/current/blk_8356562533597903371 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8426246290081429697_1167 file /tmp/hadoop-sunyan/dfs/data/current/blk_8426246290081429697 for deletion
2016-04-25 10:04:56,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2553820079981493955_1160 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2553820079981493955
2016-04-25 10:04:56,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2587576046744126236_1173 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2587576046744126236
2016-04-25 10:04:56,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3305161679708000155_1165 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3305161679708000155
2016-04-25 10:04:56,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3710839777630803774_1170 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3710839777630803774
2016-04-25 10:04:56,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4351328915959681067_1166 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4351328915959681067
2016-04-25 10:04:56,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4932533327608509314_1169 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4932533327608509314
2016-04-25 10:04:56,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6554540595342828336_1162 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6554540595342828336
2016-04-25 10:04:56,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7437308821345963474_1159 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7437308821345963474
2016-04-25 10:04:56,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8356562533597903371_1164 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8356562533597903371
2016-04-25 10:04:56,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8426246290081429697_1167 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8426246290081429697
2016-04-25 10:05:22,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6920548527668120950_1174 src: /127.0.0.1:59710 dest: /127.0.0.1:50010
2016-04-25 10:05:22,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59710, dest: /127.0.0.1:50010, bytes: 4644, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6920548527668120950_1174, duration: 2383257
2016-04-25 10:05:22,073 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6920548527668120950_1174 terminating
2016-04-25 10:05:22,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3134387390025233039_1175 src: /127.0.0.1:59711 dest: /127.0.0.1:50010
2016-04-25 10:05:22,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59711, dest: /127.0.0.1:50010, bytes: 2052, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3134387390025233039_1175, duration: 934079
2016-04-25 10:05:22,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3134387390025233039_1175 terminating
2016-04-25 10:05:22,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8810411556108395130_1176 src: /127.0.0.1:59712 dest: /127.0.0.1:50010
2016-04-25 10:05:22,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59712, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8810411556108395130_1176, duration: 1189982
2016-04-25 10:05:22,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8810411556108395130_1176 terminating
2016-04-25 10:05:22,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2645787305136360600_1177 src: /127.0.0.1:59713 dest: /127.0.0.1:50010
2016-04-25 10:05:22,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59713, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2645787305136360600_1177, duration: 1584344
2016-04-25 10:05:22,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2645787305136360600_1177 terminating
2016-04-25 10:05:22,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1780967546345960912_1178 src: /127.0.0.1:59714 dest: /127.0.0.1:50010
2016-04-25 10:05:22,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59714, dest: /127.0.0.1:50010, bytes: 3890, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1780967546345960912_1178, duration: 1107883
2016-04-25 10:05:22,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1780967546345960912_1178 terminating
2016-04-25 10:05:22,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-852047378876136087_1179 src: /127.0.0.1:59715 dest: /127.0.0.1:50010
2016-04-25 10:05:22,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59715, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-852047378876136087_1179, duration: 806256
2016-04-25 10:05:22,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-852047378876136087_1179 terminating
2016-04-25 10:05:22,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4174361359673338309_1180 src: /127.0.0.1:59716 dest: /127.0.0.1:50010
2016-04-25 10:05:22,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59716, dest: /127.0.0.1:50010, bytes: 382, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4174361359673338309_1180, duration: 1213501
2016-04-25 10:05:22,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4174361359673338309_1180 terminating
2016-04-25 10:05:22,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5113772853493544282_1181 src: /127.0.0.1:59717 dest: /127.0.0.1:50010
2016-04-25 10:05:22,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59717, dest: /127.0.0.1:50010, bytes: 2033, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5113772853493544282_1181, duration: 387850
2016-04-25 10:05:22,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5113772853493544282_1181 terminating
2016-04-25 10:05:22,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2055446367547301621_1182 src: /127.0.0.1:59718 dest: /127.0.0.1:50010
2016-04-25 10:05:22,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59718, dest: /127.0.0.1:50010, bytes: 2435, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2055446367547301621_1182, duration: 3375215
2016-04-25 10:05:22,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2055446367547301621_1182 terminating
2016-04-25 10:05:22,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5911954179389554138_1183 src: /127.0.0.1:59719 dest: /127.0.0.1:50010
2016-04-25 10:05:22,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59719, dest: /127.0.0.1:50010, bytes: 1994, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5911954179389554138_1183, duration: 758956
2016-04-25 10:05:22,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5911954179389554138_1183 terminating
2016-04-25 10:05:22,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6592541015236541658_1184 src: /127.0.0.1:59720 dest: /127.0.0.1:50010
2016-04-25 10:05:22,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59720, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6592541015236541658_1184, duration: 812196
2016-04-25 10:05:22,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6592541015236541658_1184 terminating
2016-04-25 10:05:22,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8158242112537194747_1185 src: /127.0.0.1:59721 dest: /127.0.0.1:50010
2016-04-25 10:05:22,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59721, dest: /127.0.0.1:50010, bytes: 327, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8158242112537194747_1185, duration: 405411
2016-04-25 10:05:22,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8158242112537194747_1185 terminating
2016-04-25 10:05:22,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5979878977387137403_1186 src: /127.0.0.1:59722 dest: /127.0.0.1:50010
2016-04-25 10:05:22,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59722, dest: /127.0.0.1:50010, bytes: 1095, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5979878977387137403_1186, duration: 586732
2016-04-25 10:05:22,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5979878977387137403_1186 terminating
2016-04-25 10:05:23,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7249419924975308463_1187 src: /127.0.0.1:59723 dest: /127.0.0.1:50010
2016-04-25 10:05:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59723, dest: /127.0.0.1:50010, bytes: 178, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7249419924975308463_1187, duration: 3480395
2016-04-25 10:05:23,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7249419924975308463_1187 terminating
2016-04-25 10:05:23,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1515430450728682427_1188 src: /127.0.0.1:59724 dest: /127.0.0.1:50010
2016-04-25 10:05:23,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59724, dest: /127.0.0.1:50010, bytes: 2042, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1515430450728682427_1188, duration: 1931225
2016-04-25 10:05:23,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1515430450728682427_1188 terminating
2016-04-25 10:05:23,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-648240905338386224_1189 src: /127.0.0.1:59725 dest: /127.0.0.1:50010
2016-04-25 10:05:23,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59725, dest: /127.0.0.1:50010, bytes: 5018, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-648240905338386224_1189, duration: 738751
2016-04-25 10:05:23,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-648240905338386224_1189 terminating
2016-04-25 10:05:23,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5347852087395762222_1190 src: /127.0.0.1:59726 dest: /127.0.0.1:50010
2016-04-25 10:05:23,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59726, dest: /127.0.0.1:50010, bytes: 7457, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1558201906_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5347852087395762222_1190, duration: 546573
2016-04-25 10:05:23,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5347852087395762222_1190 terminating
2016-04-25 10:06:01,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2097891661503412911_1191 src: /127.0.0.1:59730 dest: /127.0.0.1:50010
2016-04-25 10:06:01,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59730, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1179598084_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2097891661503412911_1191, duration: 5239134
2016-04-25 10:06:01,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2097891661503412911_1191 terminating
2016-04-25 10:06:01,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4896092897304862217_1192 src: /127.0.0.1:59731 dest: /127.0.0.1:50010
2016-04-25 10:06:01,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59731, dest: /127.0.0.1:50010, bytes: 2079, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1179598084_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 926142
2016-04-25 10:06:01,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4896092897304862217_1192 terminating
2016-04-25 10:06:01,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6186562963768597860_1193 src: /127.0.0.1:59732 dest: /127.0.0.1:50010
2016-04-25 10:06:01,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59732, dest: /127.0.0.1:50010, bytes: 237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1179598084_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6186562963768597860_1193, duration: 678817
2016-04-25 10:06:01,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6186562963768597860_1193 terminating
2016-04-25 10:06:01,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2899918474740647104_1194 src: /127.0.0.1:59733 dest: /127.0.0.1:50010
2016-04-25 10:06:01,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59733, dest: /127.0.0.1:50010, bytes: 33935, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1179598084_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2899918474740647104_1194, duration: 1909157
2016-04-25 10:06:01,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2899918474740647104_1194 terminating
2016-04-25 10:06:01,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8573178848332870676_1195 src: /127.0.0.1:59735 dest: /127.0.0.1:50010
2016-04-25 10:06:01,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59735, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8573178848332870676_1195, duration: 554814
2016-04-25 10:06:01,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8573178848332870676_1195 terminating
2016-04-25 10:06:01,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5444456137805588794_1196 src: /127.0.0.1:59736 dest: /127.0.0.1:50010
2016-04-25 10:06:01,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59736, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5444456137805588794_1196, duration: 2094234
2016-04-25 10:06:01,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5444456137805588794_1196 terminating
2016-04-25 10:06:01,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59738, bytes: 34203, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-674380229_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2899918474740647104_1194, duration: 645660
2016-04-25 10:06:01,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6948775239503493238_1198 src: /127.0.0.1:59739 dest: /127.0.0.1:50010
2016-04-25 10:06:01,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59739, dest: /127.0.0.1:50010, bytes: 48116, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-674380229_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6948775239503493238_1198, duration: 976628
2016-04-25 10:06:01,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6948775239503493238_1198 terminating
2016-04-25 10:06:01,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59740, bytes: 241, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-674380229_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6186562963768597860_1193, duration: 198690
2016-04-25 10:06:02,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59742, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5444456137805588794_1196, duration: 365040
2016-04-25 10:06:02,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59744, bytes: 34203, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1599011550_566, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2899918474740647104_1194, duration: 660849
2016-04-25 10:06:02,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59745, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1599011550_566, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2097891661503412911_1191, duration: 612611
2016-04-25 10:06:05,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59752, bytes: 2099, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000000_0_70007035_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 457350
2016-04-25 10:06:05,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59753, bytes: 2099, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000001_0_-1611141519_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 366588
2016-04-25 10:06:05,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59754, bytes: 5058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000001_0_-1611141519_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-648240905338386224_1189, duration: 377421
2016-04-25 10:06:05,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59755, bytes: 7517, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000000_0_70007035_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5347852087395762222_1190, duration: 247329
2016-04-25 10:06:08,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59762, bytes: 2099, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000002_0_-375031744_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 867120
2016-04-25 10:06:09,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59763, bytes: 2099, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000003_0_520165869_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 229081
2016-04-25 10:06:09,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59764, bytes: 4684, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000002_0_-375031744_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6920548527668120950_1174, duration: 220549
2016-04-25 10:06:09,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59765, bytes: 3922, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000003_0_520165869_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1780967546345960912_1178, duration: 277176
2016-04-25 10:06:11,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59770, bytes: 1583, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000005_0_420624583_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 289041
2016-04-25 10:06:11,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59771, bytes: 2099, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000004_0_-1316391122_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 292050
2016-04-25 10:06:11,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59772, bytes: 2072, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000005_0_420624583_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3134387390025233039_1175, duration: 564776
2016-04-25 10:06:11,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59773, bytes: 2455, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000004_0_-1316391122_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2055446367547301621_1182, duration: 235689
2016-04-25 10:06:13,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59777, bytes: 1583, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000006_0_892544116_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 247874
2016-04-25 10:06:13,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59778, bytes: 2058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000006_0_892544116_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1515430450728682427_1188, duration: 251500
2016-04-25 10:06:13,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59780, bytes: 1583, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000007_0_-783837571_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 484294
2016-04-25 10:06:14,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59781, bytes: 2049, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000007_0_-783837571_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5113772853493544282_1181, duration: 267677
2016-04-25 10:06:15,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59786, bytes: 1583, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000008_0_1323779812_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 278613
2016-04-25 10:06:16,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59787, bytes: 2010, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000008_0_1323779812_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5911954179389554138_1183, duration: 231901
2016-04-25 10:06:16,386 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59789, bytes: 1067, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000009_0_-81119620_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 261427
2016-04-25 10:06:16,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59790, bytes: 1107, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000009_0_-81119620_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5979878977387137403_1186, duration: 251183
2016-04-25 10:06:18,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59794, bytes: 1067, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000010_0_517085580_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 293689
2016-04-25 10:06:18,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59795, bytes: 386, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000010_0_517085580_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4174361359673338309_1180, duration: 225555
2016-04-25 10:06:18,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59797, bytes: 1067, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000011_0_2097181123_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 255663
2016-04-25 10:06:18,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59798, bytes: 331, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000011_0_2097181123_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8158242112537194747_1185, duration: 211259
2016-04-25 10:06:20,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59804, bytes: 1067, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000012_0_2135826486_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 301829
2016-04-25 10:06:20,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59805, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000012_0_2135826486_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6592541015236541658_1184, duration: 204931
2016-04-25 10:06:21,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59807, bytes: 551, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000013_0_1819881420_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 240350
2016-04-25 10:06:21,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59808, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000013_0_1819881420_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-852047378876136087_1179, duration: 187015
2016-04-25 10:06:22,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59811, bytes: 551, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000014_0_663998625_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 237501
2016-04-25 10:06:22,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59813, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000014_0_663998625_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7249419924975308463_1187, duration: 144790
2016-04-25 10:06:23,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59815, bytes: 551, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000015_0_1850988407_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 262319
2016-04-25 10:06:23,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59816, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000015_0_1850988407_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2645787305136360600_1177, duration: 217493
2016-04-25 10:06:24,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59819, bytes: 551, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000016_0_-1272921913_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4896092897304862217_1192, duration: 212219
2016-04-25 10:06:24,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59820, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0020_m_000016_0_-1272921913_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8810411556108395130_1176, duration: 162973
2016-04-25 10:06:30,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3462061787764208436_1199 src: /127.0.0.1:59825 dest: /127.0.0.1:50010
2016-04-25 10:06:30,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59825, dest: /127.0.0.1:50010, bytes: 15992, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0020_r_000000_0_937529376_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3462061787764208436_1199, duration: 2629258
2016-04-25 10:06:30,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3462061787764208436_1199 terminating
2016-04-25 10:06:33,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2771654644993690514_1200 src: /127.0.0.1:59829 dest: /127.0.0.1:50010
2016-04-25 10:06:33,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59829, dest: /127.0.0.1:50010, bytes: 57611, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-674380229_28, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2771654644993690514_1200, duration: 925670
2016-04-25 10:06:33,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2771654644993690514_1200 terminating
2016-04-25 10:06:35,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5444456137805588794_1196 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5444456137805588794 for deletion
2016-04-25 10:06:35,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2899918474740647104_1194 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2899918474740647104 for deletion
2016-04-25 10:06:35,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2097891661503412911_1191 file /tmp/hadoop-sunyan/dfs/data/current/blk_2097891661503412911 for deletion
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5444456137805588794_1196 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5444456137805588794
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4896092897304862217_1192 file /tmp/hadoop-sunyan/dfs/data/current/blk_4896092897304862217 for deletion
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2899918474740647104_1194 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2899918474740647104
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6186562963768597860_1193 file /tmp/hadoop-sunyan/dfs/data/current/blk_6186562963768597860 for deletion
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8573178848332870676_1195 file /tmp/hadoop-sunyan/dfs/data/current/blk_8573178848332870676 for deletion
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2097891661503412911_1191 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2097891661503412911
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4896092897304862217_1192 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4896092897304862217
2016-04-25 10:06:35,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6186562963768597860_1193 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6186562963768597860
2016-04-25 10:06:35,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8573178848332870676_1195 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8573178848332870676
2016-04-25 10:07:02,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59832, bytes: 16120, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2003400973_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3462061787764208436_1199, duration: 186064
2016-04-25 10:08:31,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59836, bytes: 16120, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_623170776_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3462061787764208436_1199, duration: 270326
2016-04-25 10:09:00,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-3292800536548360396_1201 src: /127.0.0.1:59840 dest: /127.0.0.1:50010
2016-04-25 10:09:00,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59840, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1039498154_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3292800536548360396_1201, duration: 5412352
2016-04-25 10:09:00,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-3292800536548360396_1201 terminating
2016-04-25 10:09:00,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7221508321426157259_1202 src: /127.0.0.1:59841 dest: /127.0.0.1:50010
2016-04-25 10:09:00,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59841, dest: /127.0.0.1:50010, bytes: 1875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1039498154_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 8987620
2016-04-25 10:09:00,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7221508321426157259_1202 terminating
2016-04-25 10:09:00,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-8270377107274833886_1203 src: /127.0.0.1:59842 dest: /127.0.0.1:50010
2016-04-25 10:09:00,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59842, dest: /127.0.0.1:50010, bytes: 236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1039498154_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8270377107274833886_1203, duration: 672269
2016-04-25 10:09:00,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-8270377107274833886_1203 terminating
2016-04-25 10:09:01,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_3500592857581062432_1204 src: /127.0.0.1:59843 dest: /127.0.0.1:50010
2016-04-25 10:09:01,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59843, dest: /127.0.0.1:50010, bytes: 34007, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1039498154_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3500592857581062432_1204, duration: 4532427
2016-04-25 10:09:01,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_3500592857581062432_1204 terminating
2016-04-25 10:09:01,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7193369716947829487_1205 src: /127.0.0.1:59845 dest: /127.0.0.1:50010
2016-04-25 10:09:01,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59845, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7193369716947829487_1205, duration: 791549
2016-04-25 10:09:01,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7193369716947829487_1205 terminating
2016-04-25 10:09:01,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6508826980419306322_1206 src: /127.0.0.1:59846 dest: /127.0.0.1:50010
2016-04-25 10:09:01,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59846, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6508826980419306322_1206, duration: 935205
2016-04-25 10:09:01,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6508826980419306322_1206 terminating
2016-04-25 10:09:01,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59848, bytes: 34275, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-461923215_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3500592857581062432_1204, duration: 191136
2016-04-25 10:09:01,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_8841916661898008393_1208 src: /127.0.0.1:59849 dest: /127.0.0.1:50010
2016-04-25 10:09:01,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59849, dest: /127.0.0.1:50010, bytes: 48188, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-461923215_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8841916661898008393_1208, duration: 834552
2016-04-25 10:09:01,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_8841916661898008393_1208 terminating
2016-04-25 10:09:01,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59850, bytes: 240, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-461923215_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-8270377107274833886_1203, duration: 312879
2016-04-25 10:09:01,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59852, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6508826980419306322_1206, duration: 307165
2016-04-25 10:09:01,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59854, bytes: 34275, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_951051647_744, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3500592857581062432_1204, duration: 354488
2016-04-25 10:09:01,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59855, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_951051647_744, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-3292800536548360396_1201, duration: 403185
2016-04-25 10:09:04,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59862, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000000_0_-776905555_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 280678
2016-04-25 10:09:05,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59863, bytes: 7517, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000000_0_-776905555_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5347852087395762222_1190, duration: 279256
2016-04-25 10:09:05,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59864, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000001_0_-1563235389_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 239722
2016-04-25 10:09:05,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59865, bytes: 5058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000001_0_-1563235389_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-648240905338386224_1189, duration: 278195
2016-04-25 10:09:08,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59871, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000002_0_957812524_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 250630
2016-04-25 10:09:08,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59873, bytes: 4684, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000002_0_957812524_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6920548527668120950_1174, duration: 242292
2016-04-25 10:09:08,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59874, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000003_0_1893082287_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 245126
2016-04-25 10:09:08,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59875, bytes: 3922, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000003_0_1893082287_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1780967546345960912_1178, duration: 246595
2016-04-25 10:09:10,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59880, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000005_0_-429145570_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 3458399
2016-04-25 10:09:11,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59881, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000004_0_-506102508_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 320527
2016-04-25 10:09:11,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59882, bytes: 2072, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000005_0_-429145570_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3134387390025233039_1175, duration: 265477
2016-04-25 10:09:11,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59883, bytes: 2455, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000004_0_-506102508_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2055446367547301621_1182, duration: 293991
2016-04-25 10:09:13,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59888, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000007_0_-2047775982_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 247233
2016-04-25 10:09:13,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59889, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000006_0_-247396676_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 290319
2016-04-25 10:09:13,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59890, bytes: 2049, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000007_0_-2047775982_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5113772853493544282_1181, duration: 270318
2016-04-25 10:09:13,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59891, bytes: 2058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000006_0_-247396676_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1515430450728682427_1188, duration: 264026
2016-04-25 10:09:16,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59897, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000008_0_-1046411586_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 264706
2016-04-25 10:09:16,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59898, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000009_0_939554460_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 477537
2016-04-25 10:09:16,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59899, bytes: 2010, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000008_0_-1046411586_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5911954179389554138_1183, duration: 242022
2016-04-25 10:09:16,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59900, bytes: 1107, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000009_0_939554460_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5979878977387137403_1186, duration: 184540
2016-04-25 10:09:18,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59904, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000010_0_-1667962670_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 171703
2016-04-25 10:09:18,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59906, bytes: 386, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000010_0_-1667962670_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4174361359673338309_1180, duration: 193838
2016-04-25 10:09:18,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59907, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000011_0_-2137740356_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 236083
2016-04-25 10:09:18,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59908, bytes: 331, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000011_0_-2137740356_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8158242112537194747_1185, duration: 177480
2016-04-25 10:09:20,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59916, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000012_0_-455742103_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 216374
2016-04-25 10:09:20,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59917, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000012_0_-455742103_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6592541015236541658_1184, duration: 194755
2016-04-25 10:09:21,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59919, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000013_0_-59206919_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 234735
2016-04-25 10:09:21,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59920, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000013_0_-59206919_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-852047378876136087_1179, duration: 172139
2016-04-25 10:09:23,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59924, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000014_0_1178190755_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 3417032
2016-04-25 10:09:23,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59925, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000014_0_1178190755_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7249419924975308463_1187, duration: 199110
2016-04-25 10:09:23,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59927, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000015_0_-1788865550_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 279358
2016-04-25 10:09:23,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59928, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000015_0_-1788865550_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2645787305136360600_1177, duration: 145611
2016-04-25 10:09:24,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59932, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000016_0_-1717384054_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7221508321426157259_1202, duration: 170347
2016-04-25 10:09:24,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59933, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0021_m_000016_0_-1717384054_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8810411556108395130_1176, duration: 151171
2016-04-25 10:09:30,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7976307341485183096_1209 src: /127.0.0.1:59936 dest: /127.0.0.1:50010
2016-04-25 10:09:30,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59936, dest: /127.0.0.1:50010, bytes: 148, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0021_r_000000_0_1401457399_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7976307341485183096_1209, duration: 2414313
2016-04-25 10:09:30,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7976307341485183096_1209 terminating
2016-04-25 10:09:32,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_2318881303678916856_1210 src: /127.0.0.1:59940 dest: /127.0.0.1:50010
2016-04-25 10:09:32,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59940, dest: /127.0.0.1:50010, bytes: 59135, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-461923215_30, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2318881303678916856_1210, duration: 1438214
2016-04-25 10:09:32,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_2318881303678916856_1210 terminating
2016-04-25 10:09:33,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5802308049946833514_1211 src: /127.0.0.1:59943 dest: /127.0.0.1:50010
2016-04-25 10:09:33,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59943, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1039498154_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5802308049946833514_1211, duration: 7561839
2016-04-25 10:09:33,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5802308049946833514_1211 terminating
2016-04-25 10:09:35,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-8270377107274833886_1203 file /tmp/hadoop-sunyan/dfs/data/current/blk_-8270377107274833886 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6508826980419306322_1206 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6508826980419306322 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-3292800536548360396_1201 file /tmp/hadoop-sunyan/dfs/data/current/blk_-3292800536548360396 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_2318881303678916856_1210 file /tmp/hadoop-sunyan/dfs/data/current/blk_2318881303678916856 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_3500592857581062432_1204 file /tmp/hadoop-sunyan/dfs/data/current/blk_3500592857581062432 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-8270377107274833886_1203 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-8270377107274833886
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7193369716947829487_1205 file /tmp/hadoop-sunyan/dfs/data/current/blk_7193369716947829487 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7221508321426157259_1202 file /tmp/hadoop-sunyan/dfs/data/current/blk_7221508321426157259 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6508826980419306322_1206 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6508826980419306322
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_7976307341485183096_1209 file /tmp/hadoop-sunyan/dfs/data/current/blk_7976307341485183096 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_8841916661898008393_1208 file /tmp/hadoop-sunyan/dfs/data/current/blk_8841916661898008393 for deletion
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-3292800536548360396_1201 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-3292800536548360396
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_2318881303678916856_1210 at file /tmp/hadoop-sunyan/dfs/data/current/blk_2318881303678916856
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_3500592857581062432_1204 at file /tmp/hadoop-sunyan/dfs/data/current/blk_3500592857581062432
2016-04-25 10:09:35,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7193369716947829487_1205 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7193369716947829487
2016-04-25 10:09:35,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7221508321426157259_1202 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7221508321426157259
2016-04-25 10:09:35,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_7976307341485183096_1209 at file /tmp/hadoop-sunyan/dfs/data/current/blk_7976307341485183096
2016-04-25 10:09:35,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_8841916661898008393_1208 at file /tmp/hadoop-sunyan/dfs/data/current/blk_8841916661898008393
2016-04-25 10:09:38,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 3ms
2016-04-25 10:09:41,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 29 blocks took 0 msec to generate and 7 msecs for RPC and NN processing
2016-04-25 10:09:48,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-5367463923243218037_1212 src: /127.0.0.1:59946 dest: /127.0.0.1:50010
2016-04-25 10:09:48,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59946, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5367463923243218037_1212, duration: 4753845
2016-04-25 10:09:48,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-5367463923243218037_1212 terminating
2016-04-25 10:09:48,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1940554389134731877_1213 src: /127.0.0.1:59947 dest: /127.0.0.1:50010
2016-04-25 10:09:48,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59947, dest: /127.0.0.1:50010, bytes: 1875, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 683446
2016-04-25 10:09:48,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1940554389134731877_1213 terminating
2016-04-25 10:09:48,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1197186099303330765_1214 src: /127.0.0.1:59948 dest: /127.0.0.1:50010
2016-04-25 10:09:48,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59948, dest: /127.0.0.1:50010, bytes: 236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1197186099303330765_1214, duration: 904304
2016-04-25 10:09:48,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1197186099303330765_1214 terminating
2016-04-25 10:09:48,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-6842555866322734894_1215 src: /127.0.0.1:59949 dest: /127.0.0.1:50010
2016-04-25 10:09:48,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59949, dest: /127.0.0.1:50010, bytes: 34008, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6842555866322734894_1215, duration: 1047406
2016-04-25 10:09:48,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-6842555866322734894_1215 terminating
2016-04-25 10:09:48,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_4382352695471529454_1216 src: /127.0.0.1:59951 dest: /127.0.0.1:50010
2016-04-25 10:09:48,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59951, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_4382352695471529454_1216, duration: 284969
2016-04-25 10:09:48,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_4382352695471529454_1216 terminating
2016-04-25 10:09:48,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-1961428226537578165_1217 src: /127.0.0.1:59952 dest: /127.0.0.1:50010
2016-04-25 10:09:48,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59952, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1961428226537578165_1217, duration: 668429
2016-04-25 10:09:48,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-1961428226537578165_1217 terminating
2016-04-25 10:09:48,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59954, bytes: 34276, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2001664883_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6842555866322734894_1215, duration: 257387
2016-04-25 10:09:48,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6337628404516688871_1219 src: /127.0.0.1:59955 dest: /127.0.0.1:50010
2016-04-25 10:09:48,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59955, dest: /127.0.0.1:50010, bytes: 48189, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2001664883_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6337628404516688871_1219, duration: 897718
2016-04-25 10:09:48,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6337628404516688871_1219 terminating
2016-04-25 10:09:48,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59956, bytes: 240, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2001664883_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1197186099303330765_1214, duration: 306725
2016-04-25 10:09:49,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59958, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1961428226537578165_1217, duration: 403735
2016-04-25 10:09:49,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59960, bytes: 34276, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_544528040_922, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6842555866322734894_1215, duration: 500874
2016-04-25 10:09:49,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59961, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_544528040_922, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5367463923243218037_1212, duration: 390378
2016-04-25 10:09:52,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59968, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000001_0_-1230271427_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 228231
2016-04-25 10:09:52,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59969, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000000_0_-248798509_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 249823
2016-04-25 10:09:52,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59970, bytes: 5058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000001_0_-1230271427_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-648240905338386224_1189, duration: 262191
2016-04-25 10:09:52,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59971, bytes: 7517, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000000_0_-248798509_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5347852087395762222_1190, duration: 267677
2016-04-25 10:09:56,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59978, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000002_0_-1885571061_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 226343
2016-04-25 10:09:56,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59979, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000003_0_-2058743630_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 271156
2016-04-25 10:09:56,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59980, bytes: 4684, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000002_0_-1885571061_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6920548527668120950_1174, duration: 242472
2016-04-25 10:09:56,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59981, bytes: 3922, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000003_0_-2058743630_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1780967546345960912_1178, duration: 363538
2016-04-25 10:09:58,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59985, bytes: 1891, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000004_0_1975111358_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 409940
2016-04-25 10:09:58,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59986, bytes: 2455, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000004_0_1975111358_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2055446367547301621_1182, duration: 257342
2016-04-25 10:09:58,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59988, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000005_0_940351712_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 240032
2016-04-25 10:09:58,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59989, bytes: 2072, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000005_0_940351712_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3134387390025233039_1175, duration: 194277
2016-04-25 10:10:00,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59993, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000006_0_1127977472_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 254832
2016-04-25 10:10:01,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59994, bytes: 2058, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000006_0_1127977472_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1515430450728682427_1188, duration: 350989
2016-04-25 10:10:01,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59996, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000007_0_-56503189_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 229650
2016-04-25 10:10:01,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:59998, bytes: 2049, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000007_0_-56503189_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5113772853493544282_1181, duration: 235393
2016-04-25 10:10:03,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60002, bytes: 1375, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000008_0_-845482021_1, offset: 512, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 810245
2016-04-25 10:10:03,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60003, bytes: 2010, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000008_0_-845482021_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5911954179389554138_1183, duration: 265772
2016-04-25 10:10:03,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60005, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000009_0_370892611_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 247517
2016-04-25 10:10:03,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60006, bytes: 1107, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000009_0_370892611_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-5979878977387137403_1186, duration: 240458
2016-04-25 10:10:05,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60010, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000010_0_28865080_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 200951
2016-04-25 10:10:05,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60011, bytes: 386, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000010_0_28865080_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4174361359673338309_1180, duration: 154482
2016-04-25 10:10:06,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60015, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000011_0_-521206668_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 231313
2016-04-25 10:10:06,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60016, bytes: 331, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000011_0_-521206668_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8158242112537194747_1185, duration: 181259
2016-04-25 10:10:08,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60020, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000012_0_1004199914_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 227355
2016-04-25 10:10:08,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60021, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000012_0_1004199914_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-6592541015236541658_1184, duration: 214647
2016-04-25 10:10:08,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60023, bytes: 859, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000013_0_-342420078_1, offset: 1024, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 213931
2016-04-25 10:10:09,052 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60024, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000013_0_-342420078_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-852047378876136087_1179, duration: 183992
2016-04-25 10:10:10,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60027, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000014_0_-1187904404_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 190631
2016-04-25 10:10:10,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60028, bytes: 182, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000014_0_-1187904404_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7249419924975308463_1187, duration: 160469
2016-04-25 10:10:11,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60032, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000015_0_1973548008_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 188892
2016-04-25 10:10:11,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60033, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000015_0_1973548008_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_2645787305136360600_1177, duration: 195745
2016-04-25 10:10:12,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60036, bytes: 343, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000016_0_-23611323_1, offset: 1536, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-1940554389134731877_1213, duration: 179687
2016-04-25 10:10:12,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60037, bytes: 14, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0023_m_000016_0_-23611323_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_8810411556108395130_1176, duration: 175422
2016-04-25 10:10:17,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_892302706560759227_1220 src: /127.0.0.1:60040 dest: /127.0.0.1:50010
2016-04-25 10:10:17,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60040, dest: /127.0.0.1:50010, bytes: 148, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0023_r_000000_0_-2061809285_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_892302706560759227_1220, duration: 2087453
2016-04-25 10:10:17,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_892302706560759227_1220 terminating
2016-04-25 10:10:20,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-2928388114765857252_1221 src: /127.0.0.1:60044 dest: /127.0.0.1:50010
2016-04-25 10:10:20,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60044, dest: /127.0.0.1:50010, bytes: 59132, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2001664883_27, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-2928388114765857252_1221, duration: 1149529
2016-04-25 10:10:20,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-2928388114765857252_1221 terminating
2016-04-25 10:10:20,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4127984992371366512_1222 src: /127.0.0.1:60047 dest: /127.0.0.1:50010
2016-04-25 10:10:20,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60047, dest: /127.0.0.1:50010, bytes: 142726, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4127984992371366512_1222, duration: 6171421
2016-04-25 10:10:20,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4127984992371366512_1222 terminating
2016-04-25 10:10:20,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4653516222246159295_1223 src: /127.0.0.1:60048 dest: /127.0.0.1:50010
2016-04-25 10:10:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60048, dest: /127.0.0.1:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4653516222246159295_1223, duration: 678848
2016-04-25 10:10:20,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4653516222246159295_1223 terminating
2016-04-25 10:10:20,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_1685466286260140156_1224 src: /127.0.0.1:60049 dest: /127.0.0.1:50010
2016-04-25 10:10:20,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60049, dest: /127.0.0.1:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1685466286260140156_1224, duration: 658109
2016-04-25 10:10:20,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_1685466286260140156_1224 terminating
2016-04-25 10:10:20,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_9052283182535301860_1225 src: /127.0.0.1:60050 dest: /127.0.0.1:50010
2016-04-25 10:10:20,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60050, dest: /127.0.0.1:50010, bytes: 33518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2048018654_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9052283182535301860_1225, duration: 1082610
2016-04-25 10:10:20,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_9052283182535301860_1225 terminating
2016-04-25 10:10:21,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5380089467476828724_1226 src: /127.0.0.1:60051 dest: /127.0.0.1:50010
2016-04-25 10:10:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60051, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5380089467476828724_1226, duration: 903207
2016-04-25 10:10:21,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5380089467476828724_1226 terminating
2016-04-25 10:10:21,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-4442033126739829039_1227 src: /127.0.0.1:60052 dest: /127.0.0.1:50010
2016-04-25 10:10:21,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60052, dest: /127.0.0.1:50010, bytes: 106, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175234663_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4442033126739829039_1227, duration: 937076
2016-04-25 10:10:21,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-4442033126739829039_1227 terminating
2016-04-25 10:10:21,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60054, bytes: 33782, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2022022074_33, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9052283182535301860_1225, duration: 211571
2016-04-25 10:10:21,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_6658537981055751796_1229 src: /127.0.0.1:60055 dest: /127.0.0.1:50010
2016-04-25 10:10:21,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60055, dest: /127.0.0.1:50010, bytes: 47466, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2022022074_33, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_6658537981055751796_1229, duration: 6280986
2016-04-25 10:10:21,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_6658537981055751796_1229 terminating
2016-04-25 10:10:21,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60056, bytes: 25, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-2022022074_33, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_1685466286260140156_1224, duration: 155806
2016-04-25 10:10:21,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60058, bytes: 110, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_431755590_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4442033126739829039_1227, duration: 336909
2016-04-25 10:10:21,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60060, bytes: 33782, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1266963366_1089, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_9052283182535301860_1225, duration: 331427
2016-04-25 10:10:21,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60061, bytes: 143842, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1266963366_1089, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4127984992371366512_1222, duration: 372814
2016-04-25 10:10:23,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-6842555866322734894_1215 file /tmp/hadoop-sunyan/dfs/data/current/blk_-6842555866322734894 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-5367463923243218037_1212 file /tmp/hadoop-sunyan/dfs/data/current/blk_-5367463923243218037 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1961428226537578165_1217 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1961428226537578165 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-6842555866322734894_1215 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-6842555866322734894
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1940554389134731877_1213 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1940554389134731877 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-1197186099303330765_1214 file /tmp/hadoop-sunyan/dfs/data/current/blk_-1197186099303330765 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_4382352695471529454_1216 file /tmp/hadoop-sunyan/dfs/data/current/blk_4382352695471529454 for deletion
2016-04-25 10:10:23,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-5367463923243218037_1212 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-5367463923243218037
2016-04-25 10:10:23,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1961428226537578165_1217 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1961428226537578165
2016-04-25 10:10:23,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1940554389134731877_1213 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1940554389134731877
2016-04-25 10:10:23,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-1197186099303330765_1214 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-1197186099303330765
2016-04-25 10:10:23,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_4382352695471529454_1216 at file /tmp/hadoop-sunyan/dfs/data/current/blk_4382352695471529454
2016-04-25 10:10:24,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60066, bytes: 129, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0024_m_000000_0_-1613939177_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-4653516222246159295_1223, duration: 178290
2016-04-25 10:10:24,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60067, bytes: 152, op: HDFS_READ, cliID: DFSClient_attempt_201604250853_0024_m_000000_0_-1613939177_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_892302706560759227_1220, duration: 180128
2016-04-25 10:10:31,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_7780699718184198839_1230 src: /127.0.0.1:60071 dest: /127.0.0.1:50010
2016-04-25 10:10:31,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60071, dest: /127.0.0.1:50010, bytes: 34, op: HDFS_WRITE, cliID: DFSClient_attempt_201604250853_0024_r_000000_0_-134966733_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7780699718184198839_1230, duration: 2925253
2016-04-25 10:10:31,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_7780699718184198839_1230 terminating
2016-04-25 10:10:34,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_5384986631923718471_1231 src: /127.0.0.1:60075 dest: /127.0.0.1:50010
2016-04-25 10:10:34,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60075, dest: /127.0.0.1:50010, bytes: 13713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2022022074_33, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_5384986631923718471_1231, duration: 1139990
2016-04-25 10:10:34,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_5384986631923718471_1231 terminating
2016-04-25 10:10:35,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4653516222246159295_1223 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4653516222246159295 for deletion
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4442033126739829039_1227 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4442033126739829039 for deletion
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-4127984992371366512_1222 file /tmp/hadoop-sunyan/dfs/data/current/blk_-4127984992371366512 for deletion
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4653516222246159295_1223 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4653516222246159295
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_1685466286260140156_1224 file /tmp/hadoop-sunyan/dfs/data/current/blk_1685466286260140156 for deletion
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_5380089467476828724_1226 file /tmp/hadoop-sunyan/dfs/data/current/blk_5380089467476828724 for deletion
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4442033126739829039_1227 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4442033126739829039
2016-04-25 10:10:35,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_9052283182535301860_1225 file /tmp/hadoop-sunyan/dfs/data/current/blk_9052283182535301860 for deletion
2016-04-25 10:10:35,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-4127984992371366512_1222 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-4127984992371366512
2016-04-25 10:10:35,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_1685466286260140156_1224 at file /tmp/hadoop-sunyan/dfs/data/current/blk_1685466286260140156
2016-04-25 10:10:35,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_5380089467476828724_1226 at file /tmp/hadoop-sunyan/dfs/data/current/blk_5380089467476828724
2016-04-25 10:10:35,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_9052283182535301860_1225 at file /tmp/hadoop-sunyan/dfs/data/current/blk_9052283182535301860
2016-04-25 10:10:38,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2928388114765857252_1221 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2928388114765857252 for deletion
2016-04-25 10:10:38,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_892302706560759227_1220 file /tmp/hadoop-sunyan/dfs/data/current/blk_892302706560759227 for deletion
2016-04-25 10:10:38,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_6337628404516688871_1219 file /tmp/hadoop-sunyan/dfs/data/current/blk_6337628404516688871 for deletion
2016-04-25 10:10:38,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2928388114765857252_1221 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2928388114765857252
2016-04-25 10:10:38,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_892302706560759227_1220 at file /tmp/hadoop-sunyan/dfs/data/current/blk_892302706560759227
2016-04-25 10:10:38,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_6337628404516688871_1219 at file /tmp/hadoop-sunyan/dfs/data/current/blk_6337628404516688871
2016-04-25 10:10:51,136 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_5104713727101707218_1081
2016-04-25 10:11:23,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60080, bytes: 38, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-1421108630_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_7780699718184198839_1230, duration: 172503
2016-04-25 10:15:24,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:60086, bytes: 16120, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_-991577148_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_3462061787764208436_1199, duration: 295950
2016-04-25 10:20:52,221 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_2771654644993690514_1200
2016-04-25 10:22:21,052 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to localhost/127.0.0.1:9000 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1150)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:1031)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1588)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:845)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:790)

2016-04-25 10:22:25,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2016-04-25 10:22:25,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
2016-04-25 10:23:15,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = myhost/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   build = https://svn.apache.org/repos/asf/hadoop/common/branches/branch-1.2 -r 1503152; compiled by 'mattf' on Mon Jul 22 15:23:09 PDT 2013
STARTUP_MSG:   java = 1.8.0_73
************************************************************/
2016-04-25 10:23:16,250 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2016-04-25 10:23:16,272 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2016-04-25 10:23:16,273 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-04-25 10:23:16,273 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2016-04-25 10:23:16,477 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2016-04-25 10:23:16,485 WARN org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Source name ugi already exists!
2016-04-25 10:23:16,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Registered FSDatasetStatusMBean
2016-04-25 10:23:16,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened data transfer server at 50010
2016-04-25 10:23:16,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2016-04-25 10:23:16,876 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2016-04-25 10:23:16,925 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-04-25 10:23:16,975 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-04-25 10:23:17,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dfs.webhdfs.enabled = false
2016-04-25 10:23:17,009 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50075
2016-04-25 10:23:17,010 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50075 webServer.getConnectors()[0].getLocalPort() returned 50075
2016-04-25 10:23:17,010 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2016-04-25 10:23:17,010 INFO org.mortbay.log: jetty-6.1.26
2016-04-25 10:23:17,413 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2016-04-25 10:23:17,419 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2016-04-25 10:23:17,420 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source DataNode registered.
2016-04-25 10:23:17,710 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort50020 registered.
2016-04-25 10:23:17,711 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort50020 registered.
2016-04-25 10:23:17,712 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2016-04-25 10:23:17,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(myhost:50010, storageID=DS-771894789-127.0.1.1-50010-1461545614190, infoPort=50075, ipcPort=50020)
2016-04-25 10:23:17,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished generating blocks being written report for 1 volumes in 0 seconds
2016-04-25 10:23:17,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 1ms
2016-04-25 10:23:17,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(127.0.0.1:50010, storageID=DS-771894789-127.0.1.1-50010-1461545614190, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/tmp/hadoop-sunyan/dfs/data/current'}
2016-04-25 10:23:17,750 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2016-04-25 10:23:17,752 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2016-04-25 10:23:17,753 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2016-04-25 10:23:17,754 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2016-04-25 10:23:17,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2016-04-25 10:23:17,754 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2016-04-25 10:23:17,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 32 blocks took 2 msec to generate and 14 msecs for RPC and NN processing
2016-04-25 10:23:17,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner
2016-04-25 10:23:17,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated rough (lockless) block report in 21 ms
2016-04-25 10:23:17,948 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_5384986631923718471_1231
2016-04-25 10:23:48,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving blk_-7805191460153862272_1232 src: /127.0.0.1:60109 dest: /127.0.0.1:50010
2016-04-25 10:23:48,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60109, dest: /127.0.0.1:50010, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576420502_1, offset: 0, srvID: DS-771894789-127.0.1.1-50010-1461545614190, blockid: blk_-7805191460153862272_1232, duration: 4289939
2016-04-25 10:23:48,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder 0 for blk_-7805191460153862272_1232 terminating
2016-04-25 10:23:50,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Scheduling blk_-2746851428874225169_1001 file /tmp/hadoop-sunyan/dfs/data/current/blk_-2746851428874225169 for deletion
2016-04-25 10:23:50,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Deleted blk_-2746851428874225169_1001 at file /tmp/hadoop-sunyan/dfs/data/current/blk_-2746851428874225169
2016-04-25 10:32:56,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 4ms
2016-04-25 10:32:59,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 32 blocks took 0 msec to generate and 4 msecs for RPC and NN processing
2016-04-25 10:33:18,059 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Verification succeeded blk_-3362722174012051584_1059
2016-04-25 10:37:33,047 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to localhost/127.0.0.1:9000 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1150)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
	at com.sun.proxy.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:1031)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1588)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:845)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:790)

2016-04-25 10:37:36,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at myhost/127.0.1.1
************************************************************/
